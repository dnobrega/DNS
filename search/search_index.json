{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DNS \u00b6 DNS is a Github repository developed by Daniel N\u00f3brega Siverio whose aim is to providing guidance in the installation and configuration of progamming languages, software packages, as well as useful information about solar telescopes and satellites, among others. About me \u00b6 I am a Postdoctoral researcher at Instituto de Astrof\u00edsica de Canarias (IAC) since the 1st of March 2021. Previously, I worked at Rosseland Centre for Solar Physics (RoCS) from the 1st of Agust 2018 until the 28th of February 2021. Papers \u00b6 18 papers in refereed journals. 281 citations. H-index: 10. Updated by 2022-01-13 (ADS) Solar surges related to UV bursts: Characterization through k-means, inversions, and density diagnosticsg. N\u00f3brega-Siverio et al. (2021) Evidence of multithermal nature of spicular downflows. Impact on solar atmospheric heating. Bose et al. (2021) Probing the Physics of the Solar Atmosphere with the Multi-slit Solar Explorer (MUSE): II. Flares and Eruptions. Cheung et al. (2021) Probing the physics of the solar atmosphere with the Multi-slit Solar Explorer (MUSE): I. Coronal Heating. De Pontieu et al. (2021b) A New View of the Solar Interface Region from the Interface Region Imaging Spectrograph (IRIS). De Pontieu et al. (2021) The chromospheric component of coronal bright points. Coronal and chromospheric responses to magnetic-flux emergence. Madjarska et al. (2021) High-resolution observations of the solar photosphere, chromosphere, and transition region. A database of coordinated IRIS and SST observations. Rouppe van der Voort et al. (2020) Case study of multi-temperature coronal jets for emerging flux MHD models. Reetika et al. (2020) Ambipolar diffusion in the Bifrost code. N\u00f3brega-Siverio et al. (2020b) Ion\u2500neutral Interactions and Nonequilibrium Ionization in the Solar Chromosphere. Mart\u00ednez-Sykora et al. (2020) Nonequilibrium ionization and ambipolar diffusion in solar magnetic flux emergence processes. N\u00f3brega-Siverio et al. (2020a) Ellerman bombs and UV bursts: reconnection at different atmospheric layers. Ortiz et al. (2020) Signatures of Magnetic Reconnection at the Footpoints of Fan-shaped Jets on a Light Bridge Driven by Photospheric Convective Motions. Bai et al. (2019) On the Importance of the Nonequilibrium Ionization of Si IV and O IV and the Line of Sight in Solar Surges. N\u00f3brega-Siverio et al. (2018) Intermittent Reconnection and Plasmoids in UV Bursts in the Low Solar Atmosphere. Rouppe van der Voort et al. (2017) Surges and Si IV Bursts in the Solar Atmosphere: Understanding IRIS and SST Observations through RMHD Experiments. N\u00f3brega-Siverio et al. (2017) Two-dimensional Radiative Magnetohydrodynamic Simulations of Partial Ionization in the Chromosphere. II. Dynamics and Energetics of the Low Solar Atmosphere. Mart\u00ednez-Sykora et al. (2017) The Cool Surge Following Flux Emergence in a Radiation-MHD Experiment. N\u00f3brega-Siverio et al. (2016) Prizes \u00b6 Early Career Researcher Prize of 2021 by the European Solar Physics Division (ESPD): ESPD news Prize for the best Astrophysics thesis of 2018 in Spain by the Sociedad Espa\u00f1ola de Astronom\u00eda (SEA): SEA news Invited talks \u00b6 Modeling solar coronal jets and surges. HINODE-14/IRIS-11 meeting. 25-29 October 2021-10 (Washington, USA). (online). Surges: a fundamental piece in the solar atmosphere puzzle. XIV.0 Reuni\u00f3n cient\u00edfica de la SEA 2020-07 (online). Modeling UV bursts. 10th IRIS meeting. 4-8 November 2019-11 (Bangalore, India). Honors & Grants \u00b6 PI of the ISSI team: Unraveling Surges: a joint perspective from numerical models, observations, and machine learning. The International Space Science Institute (ISSI), Berna, Switzerland (2021-06). PI of the computational grant: Coronal Bright Points on the Sun: a study from the photosphere to the corona (AECT-2021-1-0023). Barcelona Supercomputing Center (BSC), Spain (2021-03). Funding for Research Stay at Lockheed Martin Solar and Astrophysics Laboratory. LMSAL, Palo Alto, USA, (5 weeks, 2016/09). Funding for Research Stay at Lockheed Martin Solar and Astrophysics Laboratory. LMSAL, Palo Alto, USA, (4 weeks, 2015/08). Funding for Research Stay at Lockheed Martin Solar and Astrophysics Laboratory. LMSAL, Palo Alto, USA, (9 weeks, 2014/10). 4-year government grant to pursue doctoral studies at the IAC/ULL. Research Project 'The solar atmosphere, 3D numerical simulation of physical processes and observations'. P.I.: Prof F. Moreno Insertis (2013-09). Education \u00b6 2013 \u2013 2018 : Doctorate. Thesis: Eruptive phenomena in the solar atmosphere: radiation-MHD modeling and code development. Supervisor: Prof. Fernando Moreno Insertis Co-supervisor: Dr. Juan Mart\u00ednez Sykora Instituto de Astrof\u00edsica de Canarias (IAC) Universidad de La Laguna (ULL) 2012 \u2013 2013 : Master's Degree in Astrophysics. Master's Thesis: Magnetic flux emergence from the interior to the solar corona: reconnection, instabilities and jets. Supervisor: Prof. Fernando Moreno Insertis Co-supervisor: Dr. Juan Mart\u00ednez Sykora Instituto de Astrof\u00edsica de Canarias (IAC) Universidad de La Laguna (ULL) 2007 \u2013 2012 : Graduate in Physics. Degree's Thesis: Use of 3D numerical experiments about the solar plasma dynamics. Supervisor: Prof. Fernando Moreno Insertis Universidad de La Laguna (ULL)","title":""},{"location":"#dns","text":"DNS is a Github repository developed by Daniel N\u00f3brega Siverio whose aim is to providing guidance in the installation and configuration of progamming languages, software packages, as well as useful information about solar telescopes and satellites, among others.","title":"DNS"},{"location":"#about-me","text":"I am a Postdoctoral researcher at Instituto de Astrof\u00edsica de Canarias (IAC) since the 1st of March 2021. Previously, I worked at Rosseland Centre for Solar Physics (RoCS) from the 1st of Agust 2018 until the 28th of February 2021.","title":"About me"},{"location":"#papers","text":"18 papers in refereed journals. 281 citations. H-index: 10. Updated by 2022-01-13 (ADS) Solar surges related to UV bursts: Characterization through k-means, inversions, and density diagnosticsg. N\u00f3brega-Siverio et al. (2021) Evidence of multithermal nature of spicular downflows. Impact on solar atmospheric heating. Bose et al. (2021) Probing the Physics of the Solar Atmosphere with the Multi-slit Solar Explorer (MUSE): II. Flares and Eruptions. Cheung et al. (2021) Probing the physics of the solar atmosphere with the Multi-slit Solar Explorer (MUSE): I. Coronal Heating. De Pontieu et al. (2021b) A New View of the Solar Interface Region from the Interface Region Imaging Spectrograph (IRIS). De Pontieu et al. (2021) The chromospheric component of coronal bright points. Coronal and chromospheric responses to magnetic-flux emergence. Madjarska et al. (2021) High-resolution observations of the solar photosphere, chromosphere, and transition region. A database of coordinated IRIS and SST observations. Rouppe van der Voort et al. (2020) Case study of multi-temperature coronal jets for emerging flux MHD models. Reetika et al. (2020) Ambipolar diffusion in the Bifrost code. N\u00f3brega-Siverio et al. (2020b) Ion\u2500neutral Interactions and Nonequilibrium Ionization in the Solar Chromosphere. Mart\u00ednez-Sykora et al. (2020) Nonequilibrium ionization and ambipolar diffusion in solar magnetic flux emergence processes. N\u00f3brega-Siverio et al. (2020a) Ellerman bombs and UV bursts: reconnection at different atmospheric layers. Ortiz et al. (2020) Signatures of Magnetic Reconnection at the Footpoints of Fan-shaped Jets on a Light Bridge Driven by Photospheric Convective Motions. Bai et al. (2019) On the Importance of the Nonequilibrium Ionization of Si IV and O IV and the Line of Sight in Solar Surges. N\u00f3brega-Siverio et al. (2018) Intermittent Reconnection and Plasmoids in UV Bursts in the Low Solar Atmosphere. Rouppe van der Voort et al. (2017) Surges and Si IV Bursts in the Solar Atmosphere: Understanding IRIS and SST Observations through RMHD Experiments. N\u00f3brega-Siverio et al. (2017) Two-dimensional Radiative Magnetohydrodynamic Simulations of Partial Ionization in the Chromosphere. II. Dynamics and Energetics of the Low Solar Atmosphere. Mart\u00ednez-Sykora et al. (2017) The Cool Surge Following Flux Emergence in a Radiation-MHD Experiment. N\u00f3brega-Siverio et al. (2016)","title":"Papers"},{"location":"#prizes","text":"Early Career Researcher Prize of 2021 by the European Solar Physics Division (ESPD): ESPD news Prize for the best Astrophysics thesis of 2018 in Spain by the Sociedad Espa\u00f1ola de Astronom\u00eda (SEA): SEA news","title":"Prizes"},{"location":"#invited-talks","text":"Modeling solar coronal jets and surges. HINODE-14/IRIS-11 meeting. 25-29 October 2021-10 (Washington, USA). (online). Surges: a fundamental piece in the solar atmosphere puzzle. XIV.0 Reuni\u00f3n cient\u00edfica de la SEA 2020-07 (online). Modeling UV bursts. 10th IRIS meeting. 4-8 November 2019-11 (Bangalore, India).","title":"Invited talks"},{"location":"#honors-grants","text":"PI of the ISSI team: Unraveling Surges: a joint perspective from numerical models, observations, and machine learning. The International Space Science Institute (ISSI), Berna, Switzerland (2021-06). PI of the computational grant: Coronal Bright Points on the Sun: a study from the photosphere to the corona (AECT-2021-1-0023). Barcelona Supercomputing Center (BSC), Spain (2021-03). Funding for Research Stay at Lockheed Martin Solar and Astrophysics Laboratory. LMSAL, Palo Alto, USA, (5 weeks, 2016/09). Funding for Research Stay at Lockheed Martin Solar and Astrophysics Laboratory. LMSAL, Palo Alto, USA, (4 weeks, 2015/08). Funding for Research Stay at Lockheed Martin Solar and Astrophysics Laboratory. LMSAL, Palo Alto, USA, (9 weeks, 2014/10). 4-year government grant to pursue doctoral studies at the IAC/ULL. Research Project 'The solar atmosphere, 3D numerical simulation of physical processes and observations'. P.I.: Prof F. Moreno Insertis (2013-09).","title":"Honors &amp; Grants"},{"location":"#education","text":"2013 \u2013 2018 : Doctorate. Thesis: Eruptive phenomena in the solar atmosphere: radiation-MHD modeling and code development. Supervisor: Prof. Fernando Moreno Insertis Co-supervisor: Dr. Juan Mart\u00ednez Sykora Instituto de Astrof\u00edsica de Canarias (IAC) Universidad de La Laguna (ULL) 2012 \u2013 2013 : Master's Degree in Astrophysics. Master's Thesis: Magnetic flux emergence from the interior to the solar corona: reconnection, instabilities and jets. Supervisor: Prof. Fernando Moreno Insertis Co-supervisor: Dr. Juan Mart\u00ednez Sykora Instituto de Astrof\u00edsica de Canarias (IAC) Universidad de La Laguna (ULL) 2007 \u2013 2012 : Graduate in Physics. Degree's Thesis: Use of 3D numerical experiments about the solar plasma dynamics. Supervisor: Prof. Fernando Moreno Insertis Universidad de La Laguna (ULL)","title":"Education"},{"location":"ALMA/","text":"ALMA \u00b6 The Atacama Large Millimeter/submillimeter Array (ALMA) is a radio interferometer constructed in the Atacama Desert at 5,000 meters above sea level in the northern Republic of Chile in South America. This radio telescope is composed of 66 high-precision antennas, which operate on wavelengths of 0.32 to 3.6 mm. Its main array has fifty antennas, each with 12-meter diameters, which act together as a single telescope: an interferometer. This is complemented by a compact array of four antennas with 12-meter diameters and 12 antennas with 7-meter diameters. ALMA\u2019s antennas can be configured in different ways, spacing them at distances from 150 meters to 16 kilometers, giving ALMA a powerful \u201czoom\u201d variable, which results in images clearer than the images from the Hubble Space Telescope ( ALMA basics ). ALMA main links \u00b6 ALMA home webpage: ALMA SSALMON home webpage: SSALMON Analyzing synthetic ALMA data from Bifrost simulations: int.h5 files. \u00b6 It is necessary to clone the Bifrost code and DNS package for the following instructions. To get a list of the existing synthetic files (int.h5) within a folder, type: f = alma_synthfiles() The synthetic files contain the following variables: list = [ 'Stokes_I' , 'Tau1' , 'Wavelength' ] For instance, to read Stokes_I , type: stokes_i = alma_readsynth(f( 0 ),Stokes_I) The units of the output variables are changed in the DNS routines. ; Stokes_I : Stokes Intensity in erg/cm^2 ; We convert it to temperature: ; Stokes_I * lambda^2/Kb ; Tau1 : Optical depth in cm ; We convert it to Mm ; Wavelength : Wavelength in Angstrom ; We convert it to mm This is the list of wavelengths and their correspondence with the different ALMA bands: 0 : (lambda): 5000.000 for debugging purposes (should looks like a photosphere) Band 3 // 3.2 -> 2.77 [mm] 1 : (lambda): 32586136.73913, (freq) 92000000000.00121, (to K) 3.845497e+14 2 : (lambda): 31892814.68085, (freq) 94000000000.00017, (to K) 3.683600e+14 3 : (lambda): 31228381.04167, (freq) 95999999999.99896, (to K) 3.531715e+14 4 : (lambda): 28826197.88462, (freq) 104000000000.00137, (to K) 3.009272e+14 5 : (lambda): 28282307.35849, (freq) 105999999999.99835, (to K) 2.896786e+14 6 : (lambda): 27758560.92593, (freq) 107999999999.99969, (to K) 2.790491e+14 Band 6 // 1.30 -> 1.20 [mm] 7 : (lambda): 13091373.71179, (freq) 229000000000.00690, (to K) 6.206649e+13 8 : (lambda): 12978028.48485, (freq) 231000000000.00870, (to K) 6.099639e+13 9 : (lambda): 12866629.09871, (freq) 233000000000.00815, (to K) 5.995374e+13 10 : (lambda): 12236426.85714, (freq) 244999999999.99716, (to K) 5.422455e+13 11 : (lambda): 12137346.47773, (freq) 246999999999.99585, (to K) 5.334998e+13 12 : (lambda): 12039857.75100, (freq) 249000000000.00040, (to K) 5.249639e+13 Band 7 // 0.88 -> 0.84 [mm] 13 : (lambda): 8853882.39811, (freq) 338599999999.99500, (to K) 2.838927e+13 14 : (lambda): 8801892.48385, (freq) 340600000000.00104, (to K) 2.805685e+13 15 : (lambda): 8750509.57385, (freq) 342600000000.00214, (to K) 2.773023e+13 16 : (lambda): 8550840.21677, (freq) 350600000000.01038, (to K) 2.647917e+13 17 : (lambda): 8502338.57062, (freq) 352600000000.01105, (to K) 2.617963e+13 18 : (lambda): 8454384.03835, (freq) 354600000000.00323, (to K) 2.588515e+13 Analyzing synthetic ALMA data from Bifrost simulations: model.h5 files. \u00b6 It is necessary to clone the Bifrost code and DNS package for the following instructions. To get a list of the existing model files (model.h5) that generated the ALMA synthetic files within a folder, type: g = alma_modelfiles() The model files contain the following variables: list = [ 'Pgas' , 'temperature' , 'dens' , 'dx' , 'dy' , 'z' ] The units of the output variables are as follows: ;Pgas : Gas pressure in CGS ;temperature : Temperature in K ;dens : Total density in CGS ;dx : X axis in cm. Converted to Mm. ;dy : Y axis in Mm. Converted to Mm. ;z : Z azis in Mm. Converted to Mm.","title":"ALMA"},{"location":"ALMA/#alma","text":"The Atacama Large Millimeter/submillimeter Array (ALMA) is a radio interferometer constructed in the Atacama Desert at 5,000 meters above sea level in the northern Republic of Chile in South America. This radio telescope is composed of 66 high-precision antennas, which operate on wavelengths of 0.32 to 3.6 mm. Its main array has fifty antennas, each with 12-meter diameters, which act together as a single telescope: an interferometer. This is complemented by a compact array of four antennas with 12-meter diameters and 12 antennas with 7-meter diameters. ALMA\u2019s antennas can be configured in different ways, spacing them at distances from 150 meters to 16 kilometers, giving ALMA a powerful \u201czoom\u201d variable, which results in images clearer than the images from the Hubble Space Telescope ( ALMA basics ).","title":"ALMA"},{"location":"ALMA/#alma-main-links","text":"ALMA home webpage: ALMA SSALMON home webpage: SSALMON","title":"ALMA main links"},{"location":"ALMA/#analyzing-synthetic-alma-data-from-bifrost-simulations-inth5-files","text":"It is necessary to clone the Bifrost code and DNS package for the following instructions. To get a list of the existing synthetic files (int.h5) within a folder, type: f = alma_synthfiles() The synthetic files contain the following variables: list = [ 'Stokes_I' , 'Tau1' , 'Wavelength' ] For instance, to read Stokes_I , type: stokes_i = alma_readsynth(f( 0 ),Stokes_I) The units of the output variables are changed in the DNS routines. ; Stokes_I : Stokes Intensity in erg/cm^2 ; We convert it to temperature: ; Stokes_I * lambda^2/Kb ; Tau1 : Optical depth in cm ; We convert it to Mm ; Wavelength : Wavelength in Angstrom ; We convert it to mm This is the list of wavelengths and their correspondence with the different ALMA bands: 0 : (lambda): 5000.000 for debugging purposes (should looks like a photosphere) Band 3 // 3.2 -> 2.77 [mm] 1 : (lambda): 32586136.73913, (freq) 92000000000.00121, (to K) 3.845497e+14 2 : (lambda): 31892814.68085, (freq) 94000000000.00017, (to K) 3.683600e+14 3 : (lambda): 31228381.04167, (freq) 95999999999.99896, (to K) 3.531715e+14 4 : (lambda): 28826197.88462, (freq) 104000000000.00137, (to K) 3.009272e+14 5 : (lambda): 28282307.35849, (freq) 105999999999.99835, (to K) 2.896786e+14 6 : (lambda): 27758560.92593, (freq) 107999999999.99969, (to K) 2.790491e+14 Band 6 // 1.30 -> 1.20 [mm] 7 : (lambda): 13091373.71179, (freq) 229000000000.00690, (to K) 6.206649e+13 8 : (lambda): 12978028.48485, (freq) 231000000000.00870, (to K) 6.099639e+13 9 : (lambda): 12866629.09871, (freq) 233000000000.00815, (to K) 5.995374e+13 10 : (lambda): 12236426.85714, (freq) 244999999999.99716, (to K) 5.422455e+13 11 : (lambda): 12137346.47773, (freq) 246999999999.99585, (to K) 5.334998e+13 12 : (lambda): 12039857.75100, (freq) 249000000000.00040, (to K) 5.249639e+13 Band 7 // 0.88 -> 0.84 [mm] 13 : (lambda): 8853882.39811, (freq) 338599999999.99500, (to K) 2.838927e+13 14 : (lambda): 8801892.48385, (freq) 340600000000.00104, (to K) 2.805685e+13 15 : (lambda): 8750509.57385, (freq) 342600000000.00214, (to K) 2.773023e+13 16 : (lambda): 8550840.21677, (freq) 350600000000.01038, (to K) 2.647917e+13 17 : (lambda): 8502338.57062, (freq) 352600000000.01105, (to K) 2.617963e+13 18 : (lambda): 8454384.03835, (freq) 354600000000.00323, (to K) 2.588515e+13","title":"Analyzing synthetic ALMA data from Bifrost simulations: int.h5 files."},{"location":"ALMA/#analyzing-synthetic-alma-data-from-bifrost-simulations-modelh5-files","text":"It is necessary to clone the Bifrost code and DNS package for the following instructions. To get a list of the existing model files (model.h5) that generated the ALMA synthetic files within a folder, type: g = alma_modelfiles() The model files contain the following variables: list = [ 'Pgas' , 'temperature' , 'dens' , 'dx' , 'dy' , 'z' ] The units of the output variables are as follows: ;Pgas : Gas pressure in CGS ;temperature : Temperature in K ;dens : Total density in CGS ;dx : X axis in cm. Converted to Mm. ;dy : Y axis in Mm. Converted to Mm. ;z : Z azis in Mm. Converted to Mm.","title":"Analyzing synthetic ALMA data from Bifrost simulations: model.h5 files."},{"location":"IRIS/","text":"Cinder Theme for MkDocs IRIS \u00b6 The Interface Region Imaging Spectrograph (IRIS), is a NASA solar observation satellite. Launched on 28 June (2013), the mission was funded through the Small Explorer program to investigate the physical conditions of the solar limb, particularly the chromosphere of the Sun. The spacecraft consists of a satellite bus and spectrometer built by the Lockheed Martin Solar and Astrophysics Laboratory (LMSAL), and a telescope provided by the Smithsonian Astrophysical Observatory. IRIS is operated by LMSAL and NASA's Ames Research Center. IRIS main links \u00b6 IRIS home webpage: IRIS IRIS Science Highlights: IRIS Higlights IRIS tutorials: Tutorials IRIS Event Search: IRIS Search IRIS Event Search + Other Telescopes/Observations: HEK Search IRIS2 (a machine learning inversion tool): IRIS2 Inspecting IRIS LVL3 data with CRISPEX \u00b6 These are the to create and analyze LVL3 data with CRISPEX, for instance, IRIS+SDO/AIA data. Download IRIS raster data + SDO data in the same folder. Open a SSWIDL session in that folder Write iris_xfiles and choose the folder with the data, choose one of the .fits and then create LVL3. After that, we make a list with the name of the IRIS and SDO files: f = iris_files() Finally, crispex, f(im), f(sp), sji = f(AIA), / win For more details abour CRISPEX, please check this link: CRISPEX TUTORIAL .","title":"IRIS"},{"location":"IRIS/#iris","text":"The Interface Region Imaging Spectrograph (IRIS), is a NASA solar observation satellite. Launched on 28 June (2013), the mission was funded through the Small Explorer program to investigate the physical conditions of the solar limb, particularly the chromosphere of the Sun. The spacecraft consists of a satellite bus and spectrometer built by the Lockheed Martin Solar and Astrophysics Laboratory (LMSAL), and a telescope provided by the Smithsonian Astrophysical Observatory. IRIS is operated by LMSAL and NASA's Ames Research Center.","title":"IRIS"},{"location":"IRIS/#iris-main-links","text":"IRIS home webpage: IRIS IRIS Science Highlights: IRIS Higlights IRIS tutorials: Tutorials IRIS Event Search: IRIS Search IRIS Event Search + Other Telescopes/Observations: HEK Search IRIS2 (a machine learning inversion tool): IRIS2","title":"IRIS main links"},{"location":"IRIS/#inspecting-iris-lvl3-data-with-crispex","text":"These are the to create and analyze LVL3 data with CRISPEX, for instance, IRIS+SDO/AIA data. Download IRIS raster data + SDO data in the same folder. Open a SSWIDL session in that folder Write iris_xfiles and choose the folder with the data, choose one of the .fits and then create LVL3. After that, we make a list with the name of the IRIS and SDO files: f = iris_files() Finally, crispex, f(im), f(sp), sji = f(AIA), / win For more details abour CRISPEX, please check this link: CRISPEX TUTORIAL .","title":"Inspecting IRIS LVL3 data with CRISPEX"},{"location":"SDO/","text":"SDO \u00b6 The Solar Dynamics Observatory (SDO) is a NASA satellite, considered to be a second-generation solar mission (also referred to as SOHO successor). Launched on February 11 (2010), SDO represents the first mission within NASA's LWS (Living With a Star) program, a space weather-focused and applications-driven research program. The goal of LWS is to understand the sun as a magnetic variable star and to measure its impact on life and society on Earth. SDO main links \u00b6 SDO webpage: SDO SDO data: Data SDO/HMI: HMI HMI Science nuggets: HMI nuggets SDO/AIA: AIA SDO literature \u00b6 SDO full book: Chamberlin et al. 2012 SDO paper: Pesnell et al. 2012 SDO/HMI: Scherrer et al. 2012 SDO/AIA: Lemen et al. 2012","title":"SDO"},{"location":"SDO/#sdo","text":"The Solar Dynamics Observatory (SDO) is a NASA satellite, considered to be a second-generation solar mission (also referred to as SOHO successor). Launched on February 11 (2010), SDO represents the first mission within NASA's LWS (Living With a Star) program, a space weather-focused and applications-driven research program. The goal of LWS is to understand the sun as a magnetic variable star and to measure its impact on life and society on Earth.","title":"SDO"},{"location":"SDO/#sdo-main-links","text":"SDO webpage: SDO SDO data: Data SDO/HMI: HMI HMI Science nuggets: HMI nuggets SDO/AIA: AIA","title":"SDO main links"},{"location":"SDO/#sdo-literature","text":"SDO full book: Chamberlin et al. 2012 SDO paper: Pesnell et al. 2012 SDO/HMI: Scherrer et al. 2012 SDO/AIA: Lemen et al. 2012","title":"SDO literature"},{"location":"SOLO/","text":"Solar Orbiter (SolO) \u00b6 The Solar Orbiter mission is a M-class ESA mission from the COSMIC Vision Program, launched successfully on February 2020. Following the commissioning during spring 2020, all instruments are now working nominally. The cruise phase of the mission will extend until the end of 2021. Solar Orbiter main links \u00b6 Solar Orbiter ESA webpage: ESA Solar Orbiter conferences: CONF Solar Obiter Archive : SOAR Solar Orbiter SOC repository: SOSP SO/PHI instrument: SO/PHI EUI data: EUI SolO literature (science) \u00b6 The Solar Orbiter mission. Science overview: Science Models and data analysis tools for the Solar Orbiter mission: Models The Solar Orbiter Science Activity Plan. Translating solar and heliospheric physics questions into action: Activity Plan SolO literature (instruments) \u00b6 The Solar Orbiter Solar Wind Analyser (SWA) suite: SWA The Spectrometer/Telescope for Imaging X-rays (STIX): STIX The Solar Orbiter SPICE instrument. An extreme UV imaging spectrometer (SPICE): SPICE The Solar Orbiter Heliospheric Imager (SoloHI): SoloHI The Solar Orbiter Radio and Plasma Waves (RPW) instrument: RPW The Polarimetric and Helioseismic Imager on Solar Orbiter (SO/PHI): SO/PHI Metis: the Solar Orbiter visible light and ultraviolet coronal imager: Metis The Solar Orbiter magnetometer: SOM The Solar Orbiter EUI instrument: The Extreme Ultraviolet Imager (EUI): EUI The Energetic Particle Detector. Energetic particle instrument suite for the Solar Orbiter mission: EPD","title":"SOLO"},{"location":"SOLO/#solar-orbiter-solo","text":"The Solar Orbiter mission is a M-class ESA mission from the COSMIC Vision Program, launched successfully on February 2020. Following the commissioning during spring 2020, all instruments are now working nominally. The cruise phase of the mission will extend until the end of 2021.","title":"Solar Orbiter (SolO)"},{"location":"SOLO/#solar-orbiter-main-links","text":"Solar Orbiter ESA webpage: ESA Solar Orbiter conferences: CONF Solar Obiter Archive : SOAR Solar Orbiter SOC repository: SOSP SO/PHI instrument: SO/PHI EUI data: EUI","title":"Solar Orbiter main links"},{"location":"SOLO/#solo-literature-science","text":"The Solar Orbiter mission. Science overview: Science Models and data analysis tools for the Solar Orbiter mission: Models The Solar Orbiter Science Activity Plan. Translating solar and heliospheric physics questions into action: Activity Plan","title":"SolO literature (science)"},{"location":"SOLO/#solo-literature-instruments","text":"The Solar Orbiter Solar Wind Analyser (SWA) suite: SWA The Spectrometer/Telescope for Imaging X-rays (STIX): STIX The Solar Orbiter SPICE instrument. An extreme UV imaging spectrometer (SPICE): SPICE The Solar Orbiter Heliospheric Imager (SoloHI): SoloHI The Solar Orbiter Radio and Plasma Waves (RPW) instrument: RPW The Polarimetric and Helioseismic Imager on Solar Orbiter (SO/PHI): SO/PHI Metis: the Solar Orbiter visible light and ultraviolet coronal imager: Metis The Solar Orbiter magnetometer: SOM The Solar Orbiter EUI instrument: The Extreme Ultraviolet Imager (EUI): EUI The Energetic Particle Detector. Energetic particle instrument suite for the Solar Orbiter mission: EPD","title":"SolO literature (instruments)"},{"location":"SST/","text":"SST \u00b6 The Swedish 1-m Solar Telescope (SST) is a refracting solar telescope at Roque de los Muchachos Observatory, La Palma in the Canary Islands. The SST is capable of providing high-quality time series of spectrally resolved photospheric and chromospheric diagnostics that under excellent seeing conditions reach the diffraction limit of 0.1\" over the full arcmin^2 FOV. Furthermore, the versatile CRISP instrument can provide spectro-polarimetric data that enable measurement of the magnetic field topology. In addition, the tunable filter system CHROMIS, installed in 2016, can simultaneously provide narrowband filtergrams at several wavelengths in the core of the Ca II K line (Extracted from Rouppe et al. (2020) ). SST main links \u00b6 Overview of the observation conditions at the ORM in La Palma: Shahin's website SST wiki of RoCS: Wiki SST Observations Schedule: SST Schedule SST Data acquisitions: Data acquisitions SST literature \u00b6 The SST telescope design and its main optical elements: Scharmer et al. 2003a . The SST adaptive optics system: Scharmer et al. 2003a . The CHROMospheric Imaging Spectrometer (CHROMIS): CHROMIS webpage The CRISP imaging spectropolarimeter: Scharmer et al. 2008 Upgrades of optical components and instrumentation, as well as a thorough evaluation of optical performance: Scharmer et al. 2019 . Connecting to SST computers \u00b6 It is possible to login into the SST related computers to transfer files and to make the quicklook movies. To that end, type: ssh obs@royac6.royac.iac.es Password 3skedar Then you can type, e.g., ssh -X obs@transport1 to login into the transport1 machine. Quicklook movies and images \u00b6 ITA has now a very basic web server with the purpose of providing simple access to files ment for temporary viewing - like quicklook movies. We can put the SST quicklook movies at /mn/stornext/d18/lapalma/quicklook/ which will then appear under http://tsih3.uio.no/lapalma/ - For example, the 14-Jun quicklook movies from the LMSAL campaign are now under http://tsih3.uio.no/lapalma/2020/2020-06-14/ which are linked from the Oslo SST wiki: https://wiki.uio.no/mn/astro/lapalma/index.php/Quicklook_June_2020#Sunday_14-Jun-2020 Scripts \u00b6 A list of useful scripts that may help you (to see the code block, just click in the name): Transfer all the CRISP and CHROMIS quicklook files from SST transport1 to Oslo: #!/bin/bash #------------------------------------------------------------------------------------------ # DATE default_date = ` date + \"%Y.%m.%d\" ` read -p \"Enter date with format YYYY.MM.DD ( $default_date ): \" userdate : \" ${ userdate := $default_date } \" year = ${ userdate : 0 : 4 } month = ${ userdate : 5 : 2 } day = ${ userdate : 8 : 2 } #------------------------------------------------------------------------------------------ #------------------------------------------------------------------------------------------ # LOCATION OF THE QUICKLOOK MOVIES crisp_folder = \"/scratch/obs/ $userdate /CRISP/quicklook/\" chromis_folder = \"/scratch/obs/ $userdate /CHROMIS/quicklook/\" echo \"Preparing to transfer quicklook files from the following folders: \" echo $crisp_folder echo $chromis_folder #------------------------------------------------------------------------------------------ #------------------------------------------------------------------------------------------ # OSLO DESTINATION default_folder = \"/mn/stornext/d18/lapalma/quicklook/ $year / $year - $month - $day /\" read -p \"Enter destination at ITA ( $default_folder ): \" ita_folder : \" ${ ita_folder := $default_folder } \" #------------------------------------------------------------------------------------------ #------------------------------------------------------------------------------------------ # OSLO USER default_user = desiveri read -p \"Enter your UiO username ( $default_user ): \" username : \" ${ username := $default_user } \" #------------------------------------------------------------------------------------------ #------------------------------------------------------------------------------------------ # RSYNC TO OSLO rsync -avzP \\ --prune-empty-dirs \\ $crisp_folder $chromis_folder \\ --rsync-path = \"mkdir -p $ita_folder && rsync\" \\ $username @tsih.uio.no: $ita_folder #------------------------------------------------------------------------------------------ Combine CHROMIS quicklook movies and images: #!/bin/bash quickfile1 = $1 quickfile2 = $2 image_format = .jpg movie_format = .mov temp = * $quickfile1 * $image_format header = $( echo $temp | sed -e 's/\\(quick_...................\\).*/\\1/' ) image = $header \" ${ jj //: } \" $image_format movie = $header \" ${ jj //: } \" $movie_format ysize = $( ffprobe -v error -select_streams v:0 -show_entries stream = height -of csv = s = x:p = 0 * $quickfile1 * $image_format ) echo \"---------------------------------------------------------------------\" echo \"Creating $image \" ffmpeg -i * $quickfile1 * $image_format -i \\ * $quickfile2 * $image_format \\ -q:v 1 -filter_complex vstack = inputs = 2 $image \\ -hide_banner -loglevel error echo \"---------------------------------------------------------------------\" echo \"Creating $movie \" ffmpeg -i * $quickfile1 * $movie_format -i \\ * $quickfile2 * $movie_format \\ -filter_complex vstack = inputs = 2 \\ $movie \\ -hide_banner -loglevel error Combine CRISP quicklook movies and images: #!/bin/bash quickfile1 = $1 quickfile2 = $2 quickfile3 = $3 image_format = .jpg movie_format = .mov temp = * $quickfile1 * $image_format header = $( echo $temp | sed -e 's/\\(quick_...................\\).*/\\1/' ) image = $header \" ${ jj //: } \" $image_format movie = $header \" ${ jj //: } \" $movie_format echo \"---------------------------------------------------------------------\" echo \"Creating $image \" ffmpeg -i * $quickfile1 * $image_format -i \\ * $quickfile2 * $image_format -i \\ * $quickfile3 * $image_format \\ -q:v 1 -filter_complex hstack = inputs = 3 $image \\ -hide_banner -loglevel error echo \"---------------------------------------------------------------------\" echo \"Creating $movie \" ffmpeg -i * $quickfile1 * $movie_format -i \\ * $quickfile2 * $movie_format -i \\ * $quickfile3 * $movie_format \\ -filter_complex hstack = inputs = 3 $movie \\ -hide_banner -loglevel error Transform from pdf to png: To use this script is necessary to install ``` brew install poppler ``` which contains the main command to use (pdftoppm). Note that the instalation takes a while. After that, you can use the following script which will transform all the pdf file in the folder and subfolderes to png files. #!/bin/bash echo \"-------------------------------------------------\" echo \"Transforming from pdf to png the following files:\" filelist = ` find . -type f -name '*.pdf' ` for ii in ${ filelist } ; do echo $ii pdftoppm $ii $ii -png done See list of dates with avaialable quicklook files at ITA: #!/bin/bash for year in $( curl -s http://tsih3.uio.no/lapalma/ | grep '\\[DIR\\]' | sed 's/.*href=\"//' | sed 's/\".*//' ) ; do echo \"---------------------------\" echo $year echo \"---------------------------\" for date in $( curl -s http://tsih3.uio.no/lapalma/ $year | grep '\\[DIR\\]' | sed 's/.*href=\"//' | sed 's/\".*//' ) ; do echo $date done done Download quicklook movies from ITA by date: #!/bin/bash web = \"http://tsih3.uio.no/lapalma/\" input = $1 if [ ${# input } -eq 0 ] then folder = $web read -p \"Do you want to download all the available movies from \" $folder \" [y/n]: \" yn case $yn in [ Yy ] * ) wget -c -r -l 3 -q --show-progress --cut-dirs = 1 -nH --no-parent --reject = \"index.html*\" $folder ;; [ Nn ] * ) break ;; esac fi if [ ${# input } -eq 4 ] then folder = $web$input \"/\" wget -c -r -l 2 -q --show-progress --cut-dirs = 1 -nH --no-parent --reject = \"index.html*\" $folder fi if [ ${# input } -eq 7 ] then temp =( ${ input //-/ } ) year = ${ temp [0] } folder = $web$year \"/\" echo $folder echo ${ input } * for date in $( curl -s $folder | grep '\\[DIR\\]' | sed 's/.*href=\"//' | sed 's/\".*//' ) ; do if [[ \" $date \" == \" $input \" * ]] ; then echo $date wget -c -r -l 2 -q --show-progress --cut-dirs = 1 -nH --no-parent --reject = \"index.html*\" $folder \"/\" $date fi done fi if [ ${# input } -eq 10 ] then temp =( ${ input //-/ } ) year = ${ temp [0] } folder = $web$year \"/\" $input \"/\" wget -c -r -l 2 -q --show-progress --cut-dirs = 1 -nH --no-parent --reject = \"index.html*\" $folder fi Extract IRIS SAA times for the SST log: This scripts extracts the IRIS SAA times and copy them in your clipboard on MacOs systems. curl -s $1 | grep SAAI | awk '{print $2}' | sed -e 's/\\(:..\\).*/\\1/' > saai.txt curl -s $1 | grep SAAO | awk '{print $2}' | sed 's/\\(:..\\).*/\\1/' > saao.txt paste -d \"~\" saai.txt saao.txt | sed 's/~/ - /' | pbcopy -selection c rm saai.txt rm saao.txt The input of the script for a given day can be found within TIM in the following webpage (Please note that for weekends, the TIM link will provide the SAA dates for Saturday, Sunday and Monday): [IRIS_SAA](https://iris.lmsal.com/health-safety/timeline/) For Linux, if you have X installed you may define an equivalent to pbcopy from MacOS in this way : alias pbcopy = 'xsel --clipboard --input' alias pbpaste = 'xsel --clipboard --output' or with xclip: alias pbcopy = 'xclip -selection clipboard' alias pbpaste = 'xclip -selection clipboard -o'","title":"SST"},{"location":"SST/#sst","text":"The Swedish 1-m Solar Telescope (SST) is a refracting solar telescope at Roque de los Muchachos Observatory, La Palma in the Canary Islands. The SST is capable of providing high-quality time series of spectrally resolved photospheric and chromospheric diagnostics that under excellent seeing conditions reach the diffraction limit of 0.1\" over the full arcmin^2 FOV. Furthermore, the versatile CRISP instrument can provide spectro-polarimetric data that enable measurement of the magnetic field topology. In addition, the tunable filter system CHROMIS, installed in 2016, can simultaneously provide narrowband filtergrams at several wavelengths in the core of the Ca II K line (Extracted from Rouppe et al. (2020) ).","title":"SST"},{"location":"SST/#sst-main-links","text":"Overview of the observation conditions at the ORM in La Palma: Shahin's website SST wiki of RoCS: Wiki SST Observations Schedule: SST Schedule SST Data acquisitions: Data acquisitions","title":"SST main links"},{"location":"SST/#sst-literature","text":"The SST telescope design and its main optical elements: Scharmer et al. 2003a . The SST adaptive optics system: Scharmer et al. 2003a . The CHROMospheric Imaging Spectrometer (CHROMIS): CHROMIS webpage The CRISP imaging spectropolarimeter: Scharmer et al. 2008 Upgrades of optical components and instrumentation, as well as a thorough evaluation of optical performance: Scharmer et al. 2019 .","title":"SST literature"},{"location":"SST/#connecting-to-sst-computers","text":"It is possible to login into the SST related computers to transfer files and to make the quicklook movies. To that end, type: ssh obs@royac6.royac.iac.es Password 3skedar Then you can type, e.g., ssh -X obs@transport1 to login into the transport1 machine.","title":"Connecting to SST computers"},{"location":"SST/#quicklook-movies-and-images","text":"ITA has now a very basic web server with the purpose of providing simple access to files ment for temporary viewing - like quicklook movies. We can put the SST quicklook movies at /mn/stornext/d18/lapalma/quicklook/ which will then appear under http://tsih3.uio.no/lapalma/ - For example, the 14-Jun quicklook movies from the LMSAL campaign are now under http://tsih3.uio.no/lapalma/2020/2020-06-14/ which are linked from the Oslo SST wiki: https://wiki.uio.no/mn/astro/lapalma/index.php/Quicklook_June_2020#Sunday_14-Jun-2020","title":"Quicklook movies and images"},{"location":"SST/#scripts","text":"A list of useful scripts that may help you (to see the code block, just click in the name): Transfer all the CRISP and CHROMIS quicklook files from SST transport1 to Oslo: #!/bin/bash #------------------------------------------------------------------------------------------ # DATE default_date = ` date + \"%Y.%m.%d\" ` read -p \"Enter date with format YYYY.MM.DD ( $default_date ): \" userdate : \" ${ userdate := $default_date } \" year = ${ userdate : 0 : 4 } month = ${ userdate : 5 : 2 } day = ${ userdate : 8 : 2 } #------------------------------------------------------------------------------------------ #------------------------------------------------------------------------------------------ # LOCATION OF THE QUICKLOOK MOVIES crisp_folder = \"/scratch/obs/ $userdate /CRISP/quicklook/\" chromis_folder = \"/scratch/obs/ $userdate /CHROMIS/quicklook/\" echo \"Preparing to transfer quicklook files from the following folders: \" echo $crisp_folder echo $chromis_folder #------------------------------------------------------------------------------------------ #------------------------------------------------------------------------------------------ # OSLO DESTINATION default_folder = \"/mn/stornext/d18/lapalma/quicklook/ $year / $year - $month - $day /\" read -p \"Enter destination at ITA ( $default_folder ): \" ita_folder : \" ${ ita_folder := $default_folder } \" #------------------------------------------------------------------------------------------ #------------------------------------------------------------------------------------------ # OSLO USER default_user = desiveri read -p \"Enter your UiO username ( $default_user ): \" username : \" ${ username := $default_user } \" #------------------------------------------------------------------------------------------ #------------------------------------------------------------------------------------------ # RSYNC TO OSLO rsync -avzP \\ --prune-empty-dirs \\ $crisp_folder $chromis_folder \\ --rsync-path = \"mkdir -p $ita_folder && rsync\" \\ $username @tsih.uio.no: $ita_folder #------------------------------------------------------------------------------------------ Combine CHROMIS quicklook movies and images: #!/bin/bash quickfile1 = $1 quickfile2 = $2 image_format = .jpg movie_format = .mov temp = * $quickfile1 * $image_format header = $( echo $temp | sed -e 's/\\(quick_...................\\).*/\\1/' ) image = $header \" ${ jj //: } \" $image_format movie = $header \" ${ jj //: } \" $movie_format ysize = $( ffprobe -v error -select_streams v:0 -show_entries stream = height -of csv = s = x:p = 0 * $quickfile1 * $image_format ) echo \"---------------------------------------------------------------------\" echo \"Creating $image \" ffmpeg -i * $quickfile1 * $image_format -i \\ * $quickfile2 * $image_format \\ -q:v 1 -filter_complex vstack = inputs = 2 $image \\ -hide_banner -loglevel error echo \"---------------------------------------------------------------------\" echo \"Creating $movie \" ffmpeg -i * $quickfile1 * $movie_format -i \\ * $quickfile2 * $movie_format \\ -filter_complex vstack = inputs = 2 \\ $movie \\ -hide_banner -loglevel error Combine CRISP quicklook movies and images: #!/bin/bash quickfile1 = $1 quickfile2 = $2 quickfile3 = $3 image_format = .jpg movie_format = .mov temp = * $quickfile1 * $image_format header = $( echo $temp | sed -e 's/\\(quick_...................\\).*/\\1/' ) image = $header \" ${ jj //: } \" $image_format movie = $header \" ${ jj //: } \" $movie_format echo \"---------------------------------------------------------------------\" echo \"Creating $image \" ffmpeg -i * $quickfile1 * $image_format -i \\ * $quickfile2 * $image_format -i \\ * $quickfile3 * $image_format \\ -q:v 1 -filter_complex hstack = inputs = 3 $image \\ -hide_banner -loglevel error echo \"---------------------------------------------------------------------\" echo \"Creating $movie \" ffmpeg -i * $quickfile1 * $movie_format -i \\ * $quickfile2 * $movie_format -i \\ * $quickfile3 * $movie_format \\ -filter_complex hstack = inputs = 3 $movie \\ -hide_banner -loglevel error Transform from pdf to png: To use this script is necessary to install ``` brew install poppler ``` which contains the main command to use (pdftoppm). Note that the instalation takes a while. After that, you can use the following script which will transform all the pdf file in the folder and subfolderes to png files. #!/bin/bash echo \"-------------------------------------------------\" echo \"Transforming from pdf to png the following files:\" filelist = ` find . -type f -name '*.pdf' ` for ii in ${ filelist } ; do echo $ii pdftoppm $ii $ii -png done See list of dates with avaialable quicklook files at ITA: #!/bin/bash for year in $( curl -s http://tsih3.uio.no/lapalma/ | grep '\\[DIR\\]' | sed 's/.*href=\"//' | sed 's/\".*//' ) ; do echo \"---------------------------\" echo $year echo \"---------------------------\" for date in $( curl -s http://tsih3.uio.no/lapalma/ $year | grep '\\[DIR\\]' | sed 's/.*href=\"//' | sed 's/\".*//' ) ; do echo $date done done Download quicklook movies from ITA by date: #!/bin/bash web = \"http://tsih3.uio.no/lapalma/\" input = $1 if [ ${# input } -eq 0 ] then folder = $web read -p \"Do you want to download all the available movies from \" $folder \" [y/n]: \" yn case $yn in [ Yy ] * ) wget -c -r -l 3 -q --show-progress --cut-dirs = 1 -nH --no-parent --reject = \"index.html*\" $folder ;; [ Nn ] * ) break ;; esac fi if [ ${# input } -eq 4 ] then folder = $web$input \"/\" wget -c -r -l 2 -q --show-progress --cut-dirs = 1 -nH --no-parent --reject = \"index.html*\" $folder fi if [ ${# input } -eq 7 ] then temp =( ${ input //-/ } ) year = ${ temp [0] } folder = $web$year \"/\" echo $folder echo ${ input } * for date in $( curl -s $folder | grep '\\[DIR\\]' | sed 's/.*href=\"//' | sed 's/\".*//' ) ; do if [[ \" $date \" == \" $input \" * ]] ; then echo $date wget -c -r -l 2 -q --show-progress --cut-dirs = 1 -nH --no-parent --reject = \"index.html*\" $folder \"/\" $date fi done fi if [ ${# input } -eq 10 ] then temp =( ${ input //-/ } ) year = ${ temp [0] } folder = $web$year \"/\" $input \"/\" wget -c -r -l 2 -q --show-progress --cut-dirs = 1 -nH --no-parent --reject = \"index.html*\" $folder fi Extract IRIS SAA times for the SST log: This scripts extracts the IRIS SAA times and copy them in your clipboard on MacOs systems. curl -s $1 | grep SAAI | awk '{print $2}' | sed -e 's/\\(:..\\).*/\\1/' > saai.txt curl -s $1 | grep SAAO | awk '{print $2}' | sed 's/\\(:..\\).*/\\1/' > saao.txt paste -d \"~\" saai.txt saao.txt | sed 's/~/ - /' | pbcopy -selection c rm saai.txt rm saao.txt The input of the script for a given day can be found within TIM in the following webpage (Please note that for weekends, the TIM link will provide the SAA dates for Saturday, Sunday and Monday): [IRIS_SAA](https://iris.lmsal.com/health-safety/timeline/) For Linux, if you have X installed you may define an equivalent to pbcopy from MacOS in this way : alias pbcopy = 'xsel --clipboard --input' alias pbpaste = 'xsel --clipboard --output' or with xclip: alias pbcopy = 'xclip -selection clipboard' alias pbpaste = 'xclip -selection clipboard -o'","title":"Scripts"},{"location":"about/","text":"About me \u00b6 I am a Postdoctoral researcher at Instituto de Astrof\u00edsica de Canarias (IAC) since the 1st of March 2021. Previously, I worked at Rosseland Centre for Solar Physics (RoCS) from the 1st of Agust 2018. until the 28th of February 2021. Papers \u00b6 18 papers in refereed journals. 267 citations. H-index: 10. Updated by 2021-11-02 (ADS) . Solar surges related to UV bursts: Characterization through k-means, inversions, and density diagnosticsg. N\u00f3brega-Siverio et al. (2021) Evidence of multithermal nature of spicular downflows. Impact on solar atmospheric heating. Bose et al. (2021) Probing the Physics of the Solar Atmosphere with the Multi-slit Solar Explorer (MUSE): II. Flares and Eruptions. Cheung et al. (2021) Probing the physics of the solar atmosphere with the Multi-slit Solar Explorer (MUSE): I. Coronal Heating. De Pontieu et al. (2021b) A New View of the Solar Interface Region from the Interface Region Imaging Spectrograph (IRIS). De Pontieu et al. (2021) The chromospheric component of coronal bright points. Coronal and chromospheric responses to magnetic-flux emergence. Madjarska et al. (2021) High-resolution observations of the solar photosphere, chromosphere, and transition region. A database of coordinated IRIS and SST observations. Rouppe van der Voort et al. (2020) Case study of multi-temperature coronal jets for emerging flux MHD models. Reetika et al. (2020) Ambipolar diffusion in the Bifrost code. N\u00f3brega-Siverio et al. (2020b) Ion\u2500neutral Interactions and Nonequilibrium Ionization in the Solar Chromosphere. Mart\u00ednez-Sykora et al. (2020) Nonequilibrium ionization and ambipolar diffusion in solar magnetic flux emergence processes. N\u00f3brega-Siverio et al. (2020a) Ellerman bombs and UV bursts: reconnection at different atmospheric layers. Ortiz et al. (2020) Signatures of Magnetic Reconnection at the Footpoints of Fan-shaped Jets on a Light Bridge Driven by Photospheric Convective Motions. Bai et al. (2019) On the Importance of the Nonequilibrium Ionization of Si IV and O IV and the Line of Sight in Solar Surges. N\u00f3brega-Siverio et al. (2018) Intermittent Reconnection and Plasmoids in UV Bursts in the Low Solar Atmosphere. Rouppe van der Voort et al. (2017) Surges and Si IV Bursts in the Solar Atmosphere: Understanding IRIS and SST Observations through RMHD Experiments. N\u00f3brega-Siverio et al. (2017) Two-dimensional Radiative Magnetohydrodynamic Simulations of Partial Ionization in the Chromosphere. II. Dynamics and Energetics of the Low Solar Atmosphere. Mart\u00ednez-Sykora et al. (2017) The Cool Surge Following Flux Emergence in a Radiation-MHD Experiment. N\u00f3brega-Siverio et al. (2016) Prizes \u00b6 Early Career Researcher Prize of 2021 by the European Solar Physics Division (ESPD): ESPD news Prize for the best Astrophysics thesis of 2018 in Spain by the Sociedad Espa\u00f1ola de Astronom\u00eda (SEA): SEA news Invited talks \u00b6 Modeling solar coronal jets and surges. HINODE-14/IRIS-11 meeting. 25-29 October 2021-10 (Washington, USA). (online). Surges: a fundamental piece in the solar atmosphere puzzle. XIV.0 Reuni\u00f3n cient\u00edfica de la SEA 2020-07 (online). Modeling UV bursts. 10th IRIS meeting. 4-8 November 2019-11 (Bangalore, India). Honors & Grants \u00b6 PI of the ISSI team: Unraveling Surges: a joint perspective from numerical models, observations, and machine learning. The International Space Science Institute (ISSI), Berna, Switzerland (2021-06). PI of the computational grant: Coronal Bright Points on the Sun: a study from the photosphere to the corona (AECT-2021-1-0023). Barcelona Supercomputing Center (BSC), Spain (2021-03). Funding for Research Stay at Lockheed Martin Solar and Astrophysics Laboratory. LMSAL, Palo Alto, USA, (5 weeks, 2016/09). Funding for Research Stay at Lockheed Martin Solar and Astrophysics Laboratory. LMSAL, Palo Alto, USA, (4 weeks, 2015/08). Funding for Research Stay at Lockheed Martin Solar and Astrophysics Laboratory. LMSAL, Palo Alto, USA, (9 weeks, 2014/10). 4-year government grant to pursue doctoral studies at the IAC/ULL. Research Project 'The solar atmosphere, 3D numerical simulation of physical processes and observations'. P.I.: Prof F. Moreno Insertis (2013-09). Education \u00b6 2013 \u2013 2018 : Doctorate. Thesis: Eruptive phenomena in the solar atmosphere: radiation-MHD modeling and code development. Supervisor: Prof. Fernando Moreno Insertis Co-supervisor: Dr. Juan Mart\u00ednez Sykora Instituto de Astrof\u00edsica de Canarias (IAC) Universidad de La Laguna (ULL) 2012 \u2013 2013 : Master's Degree in Astrophysics. Master's Thesis: Magnetic flux emergence from the interior to the solar corona: reconnection, instabilities and jets. Supervisor: Prof. Fernando Moreno Insertis Co-supervisor: Dr. Juan Mart\u00ednez Sykora Instituto de Astrof\u00edsica de Canarias (IAC) Universidad de La Laguna (ULL) 2007 \u2013 2012 : Graduate in Physics. Degree's Thesis: Use of 3D numerical experiments about the solar plasma dynamics. Supervisor: Prof. Fernando Moreno Insertis Universidad de La Laguna (ULL)","title":"About"},{"location":"about/#about-me","text":"I am a Postdoctoral researcher at Instituto de Astrof\u00edsica de Canarias (IAC) since the 1st of March 2021. Previously, I worked at Rosseland Centre for Solar Physics (RoCS) from the 1st of Agust 2018. until the 28th of February 2021.","title":"About me"},{"location":"about/#papers","text":"18 papers in refereed journals. 267 citations. H-index: 10. Updated by 2021-11-02 (ADS) . Solar surges related to UV bursts: Characterization through k-means, inversions, and density diagnosticsg. N\u00f3brega-Siverio et al. (2021) Evidence of multithermal nature of spicular downflows. Impact on solar atmospheric heating. Bose et al. (2021) Probing the Physics of the Solar Atmosphere with the Multi-slit Solar Explorer (MUSE): II. Flares and Eruptions. Cheung et al. (2021) Probing the physics of the solar atmosphere with the Multi-slit Solar Explorer (MUSE): I. Coronal Heating. De Pontieu et al. (2021b) A New View of the Solar Interface Region from the Interface Region Imaging Spectrograph (IRIS). De Pontieu et al. (2021) The chromospheric component of coronal bright points. Coronal and chromospheric responses to magnetic-flux emergence. Madjarska et al. (2021) High-resolution observations of the solar photosphere, chromosphere, and transition region. A database of coordinated IRIS and SST observations. Rouppe van der Voort et al. (2020) Case study of multi-temperature coronal jets for emerging flux MHD models. Reetika et al. (2020) Ambipolar diffusion in the Bifrost code. N\u00f3brega-Siverio et al. (2020b) Ion\u2500neutral Interactions and Nonequilibrium Ionization in the Solar Chromosphere. Mart\u00ednez-Sykora et al. (2020) Nonequilibrium ionization and ambipolar diffusion in solar magnetic flux emergence processes. N\u00f3brega-Siverio et al. (2020a) Ellerman bombs and UV bursts: reconnection at different atmospheric layers. Ortiz et al. (2020) Signatures of Magnetic Reconnection at the Footpoints of Fan-shaped Jets on a Light Bridge Driven by Photospheric Convective Motions. Bai et al. (2019) On the Importance of the Nonequilibrium Ionization of Si IV and O IV and the Line of Sight in Solar Surges. N\u00f3brega-Siverio et al. (2018) Intermittent Reconnection and Plasmoids in UV Bursts in the Low Solar Atmosphere. Rouppe van der Voort et al. (2017) Surges and Si IV Bursts in the Solar Atmosphere: Understanding IRIS and SST Observations through RMHD Experiments. N\u00f3brega-Siverio et al. (2017) Two-dimensional Radiative Magnetohydrodynamic Simulations of Partial Ionization in the Chromosphere. II. Dynamics and Energetics of the Low Solar Atmosphere. Mart\u00ednez-Sykora et al. (2017) The Cool Surge Following Flux Emergence in a Radiation-MHD Experiment. N\u00f3brega-Siverio et al. (2016)","title":"Papers"},{"location":"about/#prizes","text":"Early Career Researcher Prize of 2021 by the European Solar Physics Division (ESPD): ESPD news Prize for the best Astrophysics thesis of 2018 in Spain by the Sociedad Espa\u00f1ola de Astronom\u00eda (SEA): SEA news","title":"Prizes"},{"location":"about/#invited-talks","text":"Modeling solar coronal jets and surges. HINODE-14/IRIS-11 meeting. 25-29 October 2021-10 (Washington, USA). (online). Surges: a fundamental piece in the solar atmosphere puzzle. XIV.0 Reuni\u00f3n cient\u00edfica de la SEA 2020-07 (online). Modeling UV bursts. 10th IRIS meeting. 4-8 November 2019-11 (Bangalore, India).","title":"Invited talks"},{"location":"about/#honors-grants","text":"PI of the ISSI team: Unraveling Surges: a joint perspective from numerical models, observations, and machine learning. The International Space Science Institute (ISSI), Berna, Switzerland (2021-06). PI of the computational grant: Coronal Bright Points on the Sun: a study from the photosphere to the corona (AECT-2021-1-0023). Barcelona Supercomputing Center (BSC), Spain (2021-03). Funding for Research Stay at Lockheed Martin Solar and Astrophysics Laboratory. LMSAL, Palo Alto, USA, (5 weeks, 2016/09). Funding for Research Stay at Lockheed Martin Solar and Astrophysics Laboratory. LMSAL, Palo Alto, USA, (4 weeks, 2015/08). Funding for Research Stay at Lockheed Martin Solar and Astrophysics Laboratory. LMSAL, Palo Alto, USA, (9 weeks, 2014/10). 4-year government grant to pursue doctoral studies at the IAC/ULL. Research Project 'The solar atmosphere, 3D numerical simulation of physical processes and observations'. P.I.: Prof F. Moreno Insertis (2013-09).","title":"Honors &amp; Grants"},{"location":"about/#education","text":"2013 \u2013 2018 : Doctorate. Thesis: Eruptive phenomena in the solar atmosphere: radiation-MHD modeling and code development. Supervisor: Prof. Fernando Moreno Insertis Co-supervisor: Dr. Juan Mart\u00ednez Sykora Instituto de Astrof\u00edsica de Canarias (IAC) Universidad de La Laguna (ULL) 2012 \u2013 2013 : Master's Degree in Astrophysics. Master's Thesis: Magnetic flux emergence from the interior to the solar corona: reconnection, instabilities and jets. Supervisor: Prof. Fernando Moreno Insertis Co-supervisor: Dr. Juan Mart\u00ednez Sykora Instituto de Astrof\u00edsica de Canarias (IAC) Universidad de La Laguna (ULL) 2007 \u2013 2012 : Graduate in Physics. Degree's Thesis: Use of 3D numerical experiments about the solar plasma dynamics. Supervisor: Prof. Fernando Moreno Insertis Universidad de La Laguna (ULL)","title":"Education"},{"location":"bifrost/","text":"Bifrost \u00b6 Bifrost is a massively parallel code developed for tridimensional numerical experiments of stellar atmospheres (Gudiksen et al. 2011) . In order to explicitly solve the standard partial differential equations of magnetohydrodynamics (MHD), its core uses a staggered mesh in cartesian coordinates (x,y,z) . The positioning of the variables in the mesh is as follows: the scalar variables, e.g., the density \u03c1 , are defined in the center of the numerical cells; the components of the basic vector fields, namely, the magnetic field B_i and linear momentum p_i , are located at the center of the cell faces; and the cross product or curl of those vectors, like (vxB)_i or J_i , are defined on the cell edges. The numerical scheme is a classic method of lines (MOL). It is based on a sixth order operator for the spatial derivatives. Since Bifrost uses a staggered mesh, it is not possible to avoid the use of interpolations to re-collocate the variables in space during the computations. Those interpolations are of fifth order. The time derivatives can follow a predictor-corrector scheme of third order described by Hyman (1979) or a third order Runge Kuttta method. In both cases, the timestep is controlled by the Courant-Friedrichs-Lewy (CFL) criterion (Courant et al. 1928) . In spite of using high-order methods, the numerical codes are diffusive by their own nature due to the discretization of the equations. To ensure stability, Bifrost employs a diffusive operator that consists of two main terms: a small global diffusive term and the so called hyperdiffusion term inspired by Nordlund & Galsgaard (1995) . The latter is a location-specific diffusion that acts in small regions of large gradients or jumps in the variables, like in current sheets or shocks. The advantage of using the Bifrost code is that it includes different modules that provide relevant physics for the solar atmosphere. In the following, we list the most important ones: Equation of state: Gustafsson et al. (1975) Injection of magnetic field through the bottom boundary of the convection zone: Mart\u00ednez-Sykora et al. (2008) Radiative transfer solver with coherent scattering: Skartlien (2000) and Hayek et al. (2010) Nonequilibrium ionization of Hydrogen: Leenaarts et al. (2011) Radiative transfer in the chromosphere: Carlsson and Leenaarts (2012) Generalized Ohm's Law: Mart\u00ednez-Sykora et al. (2012) Nonequilibrium ionization of optically thin ions : Olluri et al. (2013) Nonequilibrium ionization of Helium: Golding et al. (2016) Lagrangian Tracing module: Leenaarts (2018) New ambipolar diffusion module: N\u00f3brega-Siverio et al. (2020) Getting Bifrost \u00b6 Bifrost is located on github. The repository is private, meaning you should be logged in with your github username to see it at: Bifrost repository To get started with the new repository, you'll need to have git (pre-installed in most machines) and configure it to use your name and email address you registered with github, by doing something like: git config --global user.name \"Your name\" git config --global user.email username@example.com You can clone the repository through HTTPS like this: git clone https://username@github.com/ITA-Solar/Bifrost.git replacing \"username\" with your github username. Terminal configuration \u00b6 It can be useful to create (or modify) your .login (in csh/tcsh) or .zlogin (in zsh) file in your home directory to add a Bifrost system variable. In case of working with zsh: export BIFROST = \"/folder/Bifrost\" In case of tcsh: setenv BIFROST \"/folder/Bifrost\" where folder is the location where you have cloned the Bifrost repository.","title":"Bifrost"},{"location":"bifrost/#bifrost","text":"Bifrost is a massively parallel code developed for tridimensional numerical experiments of stellar atmospheres (Gudiksen et al. 2011) . In order to explicitly solve the standard partial differential equations of magnetohydrodynamics (MHD), its core uses a staggered mesh in cartesian coordinates (x,y,z) . The positioning of the variables in the mesh is as follows: the scalar variables, e.g., the density \u03c1 , are defined in the center of the numerical cells; the components of the basic vector fields, namely, the magnetic field B_i and linear momentum p_i , are located at the center of the cell faces; and the cross product or curl of those vectors, like (vxB)_i or J_i , are defined on the cell edges. The numerical scheme is a classic method of lines (MOL). It is based on a sixth order operator for the spatial derivatives. Since Bifrost uses a staggered mesh, it is not possible to avoid the use of interpolations to re-collocate the variables in space during the computations. Those interpolations are of fifth order. The time derivatives can follow a predictor-corrector scheme of third order described by Hyman (1979) or a third order Runge Kuttta method. In both cases, the timestep is controlled by the Courant-Friedrichs-Lewy (CFL) criterion (Courant et al. 1928) . In spite of using high-order methods, the numerical codes are diffusive by their own nature due to the discretization of the equations. To ensure stability, Bifrost employs a diffusive operator that consists of two main terms: a small global diffusive term and the so called hyperdiffusion term inspired by Nordlund & Galsgaard (1995) . The latter is a location-specific diffusion that acts in small regions of large gradients or jumps in the variables, like in current sheets or shocks. The advantage of using the Bifrost code is that it includes different modules that provide relevant physics for the solar atmosphere. In the following, we list the most important ones: Equation of state: Gustafsson et al. (1975) Injection of magnetic field through the bottom boundary of the convection zone: Mart\u00ednez-Sykora et al. (2008) Radiative transfer solver with coherent scattering: Skartlien (2000) and Hayek et al. (2010) Nonequilibrium ionization of Hydrogen: Leenaarts et al. (2011) Radiative transfer in the chromosphere: Carlsson and Leenaarts (2012) Generalized Ohm's Law: Mart\u00ednez-Sykora et al. (2012) Nonequilibrium ionization of optically thin ions : Olluri et al. (2013) Nonequilibrium ionization of Helium: Golding et al. (2016) Lagrangian Tracing module: Leenaarts (2018) New ambipolar diffusion module: N\u00f3brega-Siverio et al. (2020)","title":"Bifrost"},{"location":"bifrost/#getting-bifrost","text":"Bifrost is located on github. The repository is private, meaning you should be logged in with your github username to see it at: Bifrost repository To get started with the new repository, you'll need to have git (pre-installed in most machines) and configure it to use your name and email address you registered with github, by doing something like: git config --global user.name \"Your name\" git config --global user.email username@example.com You can clone the repository through HTTPS like this: git clone https://username@github.com/ITA-Solar/Bifrost.git replacing \"username\" with your github username.","title":"Getting Bifrost"},{"location":"bifrost/#terminal-configuration","text":"It can be useful to create (or modify) your .login (in csh/tcsh) or .zlogin (in zsh) file in your home directory to add a Bifrost system variable. In case of working with zsh: export BIFROST = \"/folder/Bifrost\" In case of tcsh: setenv BIFROST \"/folder/Bifrost\" where folder is the location where you have cloned the Bifrost repository.","title":"Terminal configuration"},{"location":"dns/","text":"DNS \u00b6 Getting DNS package \u00b6 You can clone the repository through HTTPS like this: git clone https://username@github.com/dnobrega/DNS.git replacing \"username\" with your github username. Terminal configuration \u00b6 It is necessary to modify your .login file in your home directory to add the following system variables. In case of working with zsh: export DNS = \"/folder/DNS\" where folder is in this case the location where you have cloned the DNS package. Then you need to add DNS path to the IDL_PATH . You should have something like this in case of using tcsh and Mac: export IDL_PATH = \"/Applications/exelis/idl85/bin\"\":+\" $BIFROST_IDL \":+\" $DNS Finally, you need to define a variable called DNS_PROJECTS with the default location where you want to save the plots and movies you are going to create with the DNS package, e.g., export DNS_PROJECTS = \"~/dns_plots\" Obviously, you will also need to create that folder. Within DNS_PROJECTS , other folders will be automatically created with the name of the simulation when you save a image or movie. Using DNS routines for Bifrost simulations \u00b6 Within a folder with a Bifrost experiment, run SSWIDL . The first plot we are going to create is a density plot: dns_plot, \"r\" ,snapt = 0 where you have to modify snapt variable with the number of snapshot you want to plot. In case of a 3D run, by default it will show the \"XZ\" plane along the whole Y-direction. You can modify which slices you want to show, e.g., dns_plot, \"r\" ,snapt = 0 , iy0 = 10 , iyf = 100 , iystep = 2 will show from index 10 to index 100 in Y-direction each two indexes. In case you want a specific slice in Y-direction, use iyt , e..g, dns_plot, \"r\" ,snapt = 0 , iyt = 300 , / png In this case we have also added the png flag to save the image as a .png file in DNS_PROJECTS folder. You can also plot animations moving in time as follows: dns_plot, \"r\" ,snap0 = 0 , snapf = 500 , step = 10 , iyt = 300 That will show the XZ plane of the simulation in the index 300 of the Y-direction from snapshot 0 to snapshot 500 each 10 snapshots. You can save the previous animation, writing dns_plot, \"r\" ,snap0 = 0 , snapf = 500 , step = 10 , iyt = 300 , / movie, / setplot That will create a movie in your DNS_PROJECTS folder. The setplot flag is to create the movie using the Z buffer device. In 3D experiments you can plot different planes, for example, dns_plot, \"r\" ,snapt = 100 , dim = \"yz\" , ixstep = 10 which will show the YZ plane each 10 indexes in X-direction. You can do the same for XY, dns_plot, \"r\" ,snapt = 100 , dim = \"xy\" , izstep = 10 You can customize your window size, thickness, colors, position of the plot... For instance, dns_plot, \"r\" ,snapt = 100 , dim = \"xy\" , izstep = 10 , xsize = 1200 , ysize = 600 , load = 39 , position = [ 0.14 , 0.08 , 0.92 , 0.74 ] Once you are happy with your plot setup, you can save it, so you will not need to write all the commands again. To do that, use dns_plot, \"r\" ,snapt = 100 , dim = \"xy\" , izstep = 10 , xsize = 1200 , ysize = 600 , load = 39 , position = [ 0.14 , 0.08 , 0.92 , 0.74 ], / save_dns_confi That will create a file in your current directory called dns_confi.sav with the plot parameters you have defined. Concerning the variables you can plot with DNS package, check dnspro/var folder. There you will see a list of routines containg each one a variable. For example, for the density, you will see a file called dnsvar_r.pro PRO dnsvar_r, d, name, snaps, swap, var, units, $ var_title = var_title, var_range = var_range, var_log = var_log, $ info = info IF KEYWORD_SET (info) THEN BEGIN message , 'Density: rho' , / info RETURN ENDIF ELSE BEGIN IF n_params () LT 6 THEN BEGIN message , 'dnsvar_r, d, name, snaps, swap, var, units, ' $ + 'var_title=var_title, var_range=var_range, var_log=var_log' , / info RETURN ENDIF CALL_PROCEDURE , \"units_\" + units, u var = d -> getvar(name,snaps,swap = swap) * u.ur var_title = '!4q!3' IF (units EQ \"solar\" ) THEN var_title = var_title + \" (g cm!u-3!n)\" var_range = [ 1.d-15 , 1.d-11 ] var_log = 1 ENDELSE END You can create all the variables following this format. So far, the list only includes the most fundamental variables. If you need help with the meaning of each variable, in the IDL prompt you can type, e.g., dnsvar_modb, / info which will show the information about the variable of that routine, in this case, % DNSVAR_MODB: Module of the magnetic field: B ( G ) Using DNS routines for SST observations \u00b6 Within a folder with reduced SST observations, run SSWIDL . Then create a string list with the names of the cube files within that folder. To that end, type fcube, f That will give you an array f of files that can be fcubes (floating-point cubes) or icubes (integer cubes). The following step is, e.g., to read the first cube of the list by writting cube = lp_read(f( 0 ),header = header) You can also run a CRISPEX session by doing the following. Let's assume your list contains the following files: 0 nb_6563_08 : 05 : 00_aligned_3950_2017 - 05 - 25T08 : 07 : 37. icube 1 nb_6563_08 : 05 : 00_aligned_3950_2017 - 05 - 25T08 : 07 : 37_sp.icube 2 hmimag_2017 - 05 - 25T08 : 07 : 37_aligned_3950_2017 - 05 - 25T08 : 07 : 37. fcube so, crispex, f[ 0 ], f[ 1 ], refcube = f[ 2 ] will start a CRSIPEX session using the Halpha data together with an HMI magnetogram as reference. Please remind that the first file has to be an image file and the second file has to be a sp (spectral) file. They are actually the same array, but ordered differently.","title":"DNSPRO"},{"location":"dns/#dns","text":"","title":"DNS"},{"location":"dns/#getting-dns-package","text":"You can clone the repository through HTTPS like this: git clone https://username@github.com/dnobrega/DNS.git replacing \"username\" with your github username.","title":"Getting DNS package"},{"location":"dns/#terminal-configuration","text":"It is necessary to modify your .login file in your home directory to add the following system variables. In case of working with zsh: export DNS = \"/folder/DNS\" where folder is in this case the location where you have cloned the DNS package. Then you need to add DNS path to the IDL_PATH . You should have something like this in case of using tcsh and Mac: export IDL_PATH = \"/Applications/exelis/idl85/bin\"\":+\" $BIFROST_IDL \":+\" $DNS Finally, you need to define a variable called DNS_PROJECTS with the default location where you want to save the plots and movies you are going to create with the DNS package, e.g., export DNS_PROJECTS = \"~/dns_plots\" Obviously, you will also need to create that folder. Within DNS_PROJECTS , other folders will be automatically created with the name of the simulation when you save a image or movie.","title":"Terminal configuration"},{"location":"dns/#using-dns-routines-for-bifrost-simulations","text":"Within a folder with a Bifrost experiment, run SSWIDL . The first plot we are going to create is a density plot: dns_plot, \"r\" ,snapt = 0 where you have to modify snapt variable with the number of snapshot you want to plot. In case of a 3D run, by default it will show the \"XZ\" plane along the whole Y-direction. You can modify which slices you want to show, e.g., dns_plot, \"r\" ,snapt = 0 , iy0 = 10 , iyf = 100 , iystep = 2 will show from index 10 to index 100 in Y-direction each two indexes. In case you want a specific slice in Y-direction, use iyt , e..g, dns_plot, \"r\" ,snapt = 0 , iyt = 300 , / png In this case we have also added the png flag to save the image as a .png file in DNS_PROJECTS folder. You can also plot animations moving in time as follows: dns_plot, \"r\" ,snap0 = 0 , snapf = 500 , step = 10 , iyt = 300 That will show the XZ plane of the simulation in the index 300 of the Y-direction from snapshot 0 to snapshot 500 each 10 snapshots. You can save the previous animation, writing dns_plot, \"r\" ,snap0 = 0 , snapf = 500 , step = 10 , iyt = 300 , / movie, / setplot That will create a movie in your DNS_PROJECTS folder. The setplot flag is to create the movie using the Z buffer device. In 3D experiments you can plot different planes, for example, dns_plot, \"r\" ,snapt = 100 , dim = \"yz\" , ixstep = 10 which will show the YZ plane each 10 indexes in X-direction. You can do the same for XY, dns_plot, \"r\" ,snapt = 100 , dim = \"xy\" , izstep = 10 You can customize your window size, thickness, colors, position of the plot... For instance, dns_plot, \"r\" ,snapt = 100 , dim = \"xy\" , izstep = 10 , xsize = 1200 , ysize = 600 , load = 39 , position = [ 0.14 , 0.08 , 0.92 , 0.74 ] Once you are happy with your plot setup, you can save it, so you will not need to write all the commands again. To do that, use dns_plot, \"r\" ,snapt = 100 , dim = \"xy\" , izstep = 10 , xsize = 1200 , ysize = 600 , load = 39 , position = [ 0.14 , 0.08 , 0.92 , 0.74 ], / save_dns_confi That will create a file in your current directory called dns_confi.sav with the plot parameters you have defined. Concerning the variables you can plot with DNS package, check dnspro/var folder. There you will see a list of routines containg each one a variable. For example, for the density, you will see a file called dnsvar_r.pro PRO dnsvar_r, d, name, snaps, swap, var, units, $ var_title = var_title, var_range = var_range, var_log = var_log, $ info = info IF KEYWORD_SET (info) THEN BEGIN message , 'Density: rho' , / info RETURN ENDIF ELSE BEGIN IF n_params () LT 6 THEN BEGIN message , 'dnsvar_r, d, name, snaps, swap, var, units, ' $ + 'var_title=var_title, var_range=var_range, var_log=var_log' , / info RETURN ENDIF CALL_PROCEDURE , \"units_\" + units, u var = d -> getvar(name,snaps,swap = swap) * u.ur var_title = '!4q!3' IF (units EQ \"solar\" ) THEN var_title = var_title + \" (g cm!u-3!n)\" var_range = [ 1.d-15 , 1.d-11 ] var_log = 1 ENDELSE END You can create all the variables following this format. So far, the list only includes the most fundamental variables. If you need help with the meaning of each variable, in the IDL prompt you can type, e.g., dnsvar_modb, / info which will show the information about the variable of that routine, in this case, % DNSVAR_MODB: Module of the magnetic field: B ( G )","title":"Using DNS routines for Bifrost simulations"},{"location":"dns/#using-dns-routines-for-sst-observations","text":"Within a folder with reduced SST observations, run SSWIDL . Then create a string list with the names of the cube files within that folder. To that end, type fcube, f That will give you an array f of files that can be fcubes (floating-point cubes) or icubes (integer cubes). The following step is, e.g., to read the first cube of the list by writting cube = lp_read(f( 0 ),header = header) You can also run a CRISPEX session by doing the following. Let's assume your list contains the following files: 0 nb_6563_08 : 05 : 00_aligned_3950_2017 - 05 - 25T08 : 07 : 37. icube 1 nb_6563_08 : 05 : 00_aligned_3950_2017 - 05 - 25T08 : 07 : 37_sp.icube 2 hmimag_2017 - 05 - 25T08 : 07 : 37_aligned_3950_2017 - 05 - 25T08 : 07 : 37. fcube so, crispex, f[ 0 ], f[ 1 ], refcube = f[ 2 ] will start a CRSIPEX session using the Halpha data together with an HMI magnetogram as reference. Please remind that the first file has to be an image file and the second file has to be a sp (spectral) file. They are actually the same array, but ordered differently.","title":"Using DNS routines for SST observations"},{"location":"idl/","text":"IDL in Bifrost \u00b6 First steps \u00b6 In your home directory, check your .zlogin file to see if you have defined the following variables: IDL_DIR and IDL_PATH . In case of using Mac and tcsh, you should have something like this: export IDL_PATH = \"/Applications/exelis/idl85/bin\" export IDL_DIR = \"/Applications/exelis/idl85/\" including the IDL_PATH in your PATH : export PATH = $PATH \":\" $IDL_PATH In addition to that, you need to have installed Solar Soft IDL (SSWIDL). Check the documentation in SSWIDL Terminal configuration to use the IDL routines of Bifrost \u00b6 Modify your .zlogin file to add the following system variables. In case of working with tcsh: export BIFROST_IDL = $BIFROST \"/IDL\" where BIFROST is a system variable for your Bifrost repository (see Bifrost section). Then, modifiy your IDL_PATH to the the Bifrost IDL folder: export IDL_PATH = \"/Applications/exelis/idl85/bin\"\":+\" $BIFROST_IDL It is also necessary to define a system variable called OSC_CSTAGGER , which depends on your operative system. If you use a Linux system: export OSC_CSTAGGER = $BIFROST_IDL \"/cstagger/linux\" In case of a intelmac: export OSC_CSTAGGER = $BIFROST_IDL \"/cstagger/intelmac\" Stagger configuration \u00b6 Next step is to go to your stagger folder, typing in your terminal cd $OSC_CSTAGGER and then make That would create the following six files: cstagger.pro cstagger.c cstagger.o init_stagger.o inverse.o cstagger.so which are necessary for stagger operations. IDL startup \u00b6 After all this steps, create a IDL startup file. This file is going to be executed automatically each time IDL is started. For example, you can create it in your IDLWorkspace and then add a similar line in your .login file (in case of using tcsh) with the location: export IDL_STARTUP = \"/Users/yourname/IDLWorkspace85/startup.pro\" Edit the startup.pro file to add the following line .r $OSC_CSTAGGER / cstagger whici will compile the Stagger routines each time you execute IDL. With all the information above, you should be able to use the IDL routines of Bifrost without any problem. I also have the following useful lines in startup.pro br_select_idlparam, idlparam d = obj_new ( 'br_data' , idlparam) br_getsnapind, idlparam, snaps PRINT , '%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%' PRINT , ' Project : ' , idlparam, ' ' , strtrim ( string ( min (snaps)), 2 ), '-' , strtrim ( string ( max (snaps)), 2 ) PRINT , '%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%' PRINT , ' so everytime I run IDL within a folder containing a numerical experiment carried out with Bifrost, I get the object to load Bifrost variables ( d ), the name of the simulation ( idlparam ) and all the snapshots I have in that folder ( snaps ). Then I print on the screen some of that information.","title":"IDL"},{"location":"idl/#idl-in-bifrost","text":"","title":"IDL in Bifrost"},{"location":"idl/#first-steps","text":"In your home directory, check your .zlogin file to see if you have defined the following variables: IDL_DIR and IDL_PATH . In case of using Mac and tcsh, you should have something like this: export IDL_PATH = \"/Applications/exelis/idl85/bin\" export IDL_DIR = \"/Applications/exelis/idl85/\" including the IDL_PATH in your PATH : export PATH = $PATH \":\" $IDL_PATH In addition to that, you need to have installed Solar Soft IDL (SSWIDL). Check the documentation in SSWIDL","title":"First steps"},{"location":"idl/#terminal-configuration-to-use-the-idl-routines-of-bifrost","text":"Modify your .zlogin file to add the following system variables. In case of working with tcsh: export BIFROST_IDL = $BIFROST \"/IDL\" where BIFROST is a system variable for your Bifrost repository (see Bifrost section). Then, modifiy your IDL_PATH to the the Bifrost IDL folder: export IDL_PATH = \"/Applications/exelis/idl85/bin\"\":+\" $BIFROST_IDL It is also necessary to define a system variable called OSC_CSTAGGER , which depends on your operative system. If you use a Linux system: export OSC_CSTAGGER = $BIFROST_IDL \"/cstagger/linux\" In case of a intelmac: export OSC_CSTAGGER = $BIFROST_IDL \"/cstagger/intelmac\"","title":"Terminal configuration to use the IDL routines of Bifrost"},{"location":"idl/#stagger-configuration","text":"Next step is to go to your stagger folder, typing in your terminal cd $OSC_CSTAGGER and then make That would create the following six files: cstagger.pro cstagger.c cstagger.o init_stagger.o inverse.o cstagger.so which are necessary for stagger operations.","title":"Stagger configuration"},{"location":"idl/#idl-startup","text":"After all this steps, create a IDL startup file. This file is going to be executed automatically each time IDL is started. For example, you can create it in your IDLWorkspace and then add a similar line in your .login file (in case of using tcsh) with the location: export IDL_STARTUP = \"/Users/yourname/IDLWorkspace85/startup.pro\" Edit the startup.pro file to add the following line .r $OSC_CSTAGGER / cstagger whici will compile the Stagger routines each time you execute IDL. With all the information above, you should be able to use the IDL routines of Bifrost without any problem. I also have the following useful lines in startup.pro br_select_idlparam, idlparam d = obj_new ( 'br_data' , idlparam) br_getsnapind, idlparam, snaps PRINT , '%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%' PRINT , ' Project : ' , idlparam, ' ' , strtrim ( string ( min (snaps)), 2 ), '-' , strtrim ( string ( max (snaps)), 2 ) PRINT , '%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%' PRINT , ' so everytime I run IDL within a folder containing a numerical experiment carried out with Bifrost, I get the object to load Bifrost variables ( d ), the name of the simulation ( idlparam ) and all the snapshots I have in that folder ( snaps ). Then I print on the screen some of that information.","title":"IDL startup"},{"location":"macos/","text":"Mac OS \u00b6 This list contains useful software you should install when using a Mac for the first time. Xcode \u00b6 Xcode is an integrated development environment for macOS containing a suite of software development tools developed by Apple. You can download and install it from the Apple store. You can also check the following link: Xcode . Oh my zsh \u00b6 A delightful community-driven (with 1700+ contributors) framework for managing your zsh configuration. Includes 200+ optional plugins (rails, git, OSX, hub, capistrano, brew, ant, php, python, etc), over 140 themes to spice up your morning, and an auto-update tool so that makes it easy to keep up with the latest updates from the community: ohmyzsh Emacs \u00b6 Emacs is the extensible, customizable, self-documenting real-time display editor. Download the .dmg file from here: Emacs After installing Emacs, it is useful to define a new alias. In case of using zsh, modify your .zshrc file to include alias emacs = \"emacs -nw\" This will let you open any file in the terminal and not in a new extra annoying and time-consuming window. Homebrew \u00b6 Homebrew is the Missing Package Manager for macOS: Homebrew GCC \u00b6 The GNU Compiler Collection includes front ends for C, C++, Objective-C, Fortran, Ada, Go, and D, as well as libraries for these languages (libstdc++,...). GCC was originally written as the compiler for the GNU operating system. The GNU system was developed to be 100% free software, free in the sense that it respects the user's freedom. Install it after having homebrew by typing brew install gcc MPICH \u00b6 MPICH is a high performance and widely portable implementation of the Message Passing Interface (MPI) standard. You can install it through homebrew following the instructions here: MPICH","title":"Mac OS"},{"location":"macos/#mac-os","text":"This list contains useful software you should install when using a Mac for the first time.","title":"Mac OS"},{"location":"macos/#xcode","text":"Xcode is an integrated development environment for macOS containing a suite of software development tools developed by Apple. You can download and install it from the Apple store. You can also check the following link: Xcode .","title":"Xcode"},{"location":"macos/#oh-my-zsh","text":"A delightful community-driven (with 1700+ contributors) framework for managing your zsh configuration. Includes 200+ optional plugins (rails, git, OSX, hub, capistrano, brew, ant, php, python, etc), over 140 themes to spice up your morning, and an auto-update tool so that makes it easy to keep up with the latest updates from the community: ohmyzsh","title":"Oh my zsh"},{"location":"macos/#emacs","text":"Emacs is the extensible, customizable, self-documenting real-time display editor. Download the .dmg file from here: Emacs After installing Emacs, it is useful to define a new alias. In case of using zsh, modify your .zshrc file to include alias emacs = \"emacs -nw\" This will let you open any file in the terminal and not in a new extra annoying and time-consuming window.","title":"Emacs"},{"location":"macos/#homebrew","text":"Homebrew is the Missing Package Manager for macOS: Homebrew","title":"Homebrew"},{"location":"macos/#gcc","text":"The GNU Compiler Collection includes front ends for C, C++, Objective-C, Fortran, Ada, Go, and D, as well as libraries for these languages (libstdc++,...). GCC was originally written as the compiler for the GNU operating system. The GNU system was developed to be 100% free software, free in the sense that it respects the user's freedom. Install it after having homebrew by typing brew install gcc","title":"GCC"},{"location":"macos/#mpich","text":"MPICH is a high performance and widely portable implementation of the Message Passing Interface (MPI) standard. You can install it through homebrew following the instructions here: MPICH","title":"MPICH"},{"location":"python/","text":"Python \u00b6 Python is an interpreted, high-level and general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects. In the following, you can find some useful links to install Anaconda and interesting Python libraries as well as specific tutorials. Anaconda \u00b6 Anaconda is a package manager, an environment manager, a Python/R data science distribution, and a collection of over 7,500+ open-source packages. See the instructions for the installation here: Anaconda After the installation, typing in the terminal python --version you should get the latest version of Python from Anaconda (3.8.3 at the moment of writing this). If you get an older version, then modify your PATH to include Anaconda. For Mac under zsh, modify the .zlogin file in your home directory as follows: export ANACONDA_DIR = \"/Users/username/opt/anaconda3/bin\" export PATH = $ANACONDA_DIR \":\" $PATH Helita \u00b6 Helita is a Python library for solar physics focused on interfacing with code and projects from the Institute of Theoretical Astrophysics (ITA) and the Rosseland Centre for Solar Physics (RoCS) at the University of Oslo. It contains routines to read SST observations and Bifrost simulations. You can install it through pip or cloning the directory from github, namely, pip install git+https://github.com/ITA-Solar/helita.git@master or git clone https://github.com/ITA-solar/helita.git cd helita python setup.py install For further details, check Helita IRISpy \u00b6 Python library to analyze IRIS Level 2 data: IRISpy It is probable that to run IRISSpy for the first ime, the only library is missing to install is pyqtgraph , so type in the terminal conda install pyqtgraph If everything is properly installed, you should be able to open a python session and type import iris_lmsalpy as iris without any problem. AIApy \u00b6 AIApy is a Python package for analyzing data from the Atmospheric Imaging Assembly (AIA) instrument onboard the Solar Dynamics Observatory spacecraft. It includes software for converting AIA images from level 1 to level 1.5, point spread function deconvolution, and computing the wavelength and temperature response functions for the EUV channels: AIApy SunPy \u00b6 SunPy is an open-source Python library for Solar Physics data analysis and visualization: Sunpy scikit-learn \u00b6 Scikit-learn (formerly scikits.learn and also known as sklearn) is a free software machine learning library for the Python programming language.[2] It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy: scikit-learn SciPy meeting \u00b6 The annual SciPy Conferences allows participants from academic, commercial, and governmental organizations to: - showcase their latest Scientific Python projects, - learn from skilled users and developers, and - collaborate on code development. The conferences generally consists of multiple days of tutorials followed by two-three days of presentations, and concludes with 1-2 days developer sprints on projects of interest to the attendees. https://conference.scipy.org/ Some tutorials from SciPy meeting \u00b6 Dask (multi-core execution on larger-than-memory datasets): Dask tutorial Deep learning from scratch with pytorch: Deep learning tutorial Jupyter widget ecosystem: Widget tutorial","title":"Python"},{"location":"python/#python","text":"Python is an interpreted, high-level and general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects. In the following, you can find some useful links to install Anaconda and interesting Python libraries as well as specific tutorials.","title":"Python"},{"location":"python/#anaconda","text":"Anaconda is a package manager, an environment manager, a Python/R data science distribution, and a collection of over 7,500+ open-source packages. See the instructions for the installation here: Anaconda After the installation, typing in the terminal python --version you should get the latest version of Python from Anaconda (3.8.3 at the moment of writing this). If you get an older version, then modify your PATH to include Anaconda. For Mac under zsh, modify the .zlogin file in your home directory as follows: export ANACONDA_DIR = \"/Users/username/opt/anaconda3/bin\" export PATH = $ANACONDA_DIR \":\" $PATH","title":"Anaconda"},{"location":"python/#helita","text":"Helita is a Python library for solar physics focused on interfacing with code and projects from the Institute of Theoretical Astrophysics (ITA) and the Rosseland Centre for Solar Physics (RoCS) at the University of Oslo. It contains routines to read SST observations and Bifrost simulations. You can install it through pip or cloning the directory from github, namely, pip install git+https://github.com/ITA-Solar/helita.git@master or git clone https://github.com/ITA-solar/helita.git cd helita python setup.py install For further details, check Helita","title":"Helita"},{"location":"python/#irispy","text":"Python library to analyze IRIS Level 2 data: IRISpy It is probable that to run IRISSpy for the first ime, the only library is missing to install is pyqtgraph , so type in the terminal conda install pyqtgraph If everything is properly installed, you should be able to open a python session and type import iris_lmsalpy as iris without any problem.","title":"IRISpy"},{"location":"python/#aiapy","text":"AIApy is a Python package for analyzing data from the Atmospheric Imaging Assembly (AIA) instrument onboard the Solar Dynamics Observatory spacecraft. It includes software for converting AIA images from level 1 to level 1.5, point spread function deconvolution, and computing the wavelength and temperature response functions for the EUV channels: AIApy","title":"AIApy"},{"location":"python/#sunpy","text":"SunPy is an open-source Python library for Solar Physics data analysis and visualization: Sunpy","title":"SunPy"},{"location":"python/#scikit-learn","text":"Scikit-learn (formerly scikits.learn and also known as sklearn) is a free software machine learning library for the Python programming language.[2] It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy: scikit-learn","title":"scikit-learn"},{"location":"python/#scipy-meeting","text":"The annual SciPy Conferences allows participants from academic, commercial, and governmental organizations to: - showcase their latest Scientific Python projects, - learn from skilled users and developers, and - collaborate on code development. The conferences generally consists of multiple days of tutorials followed by two-three days of presentations, and concludes with 1-2 days developer sprints on projects of interest to the attendees. https://conference.scipy.org/","title":"SciPy meeting"},{"location":"python/#some-tutorials-from-scipy-meeting","text":"Dask (multi-core execution on larger-than-memory datasets): Dask tutorial Deep learning from scratch with pytorch: Deep learning tutorial Jupyter widget ecosystem: Widget tutorial","title":"Some tutorials from SciPy meeting"},{"location":"sswidl/","text":"SSWIDL \u00b6 SolarSoft is a set of integrated software libraries, data bases, and system utilities which provide a common programming and data analysis environment for Solar Physics. It is primarily an IDL based system, although some instrument teams integrate executables written in other languages. Installation \u00b6 SSWIDL can be only used in csh/tcsh terminals, but we can configurate our terminal to launch without having to switch (see below). To install it, follow these instructions: SSWIDL_INSTALL . Choose, e.g., the following packages to install: chianti ontology aia iris hmi Terminal configuration \u00b6 Once installed, configurate your csh/tcsh terminal to use SSWIDL. In your home directory, in the .login file you need to define the system variable SSW as the location of your SSW installation, e.g.: setenv SSW \"/Users/yourname/ssw\" Then you need to define the SSW_INSTR with the list of instruments you have included in the installation. setenv SSW_INSTR \"chianti ontology aia iris hmi\" Finally, add the following line in your .login file: source $SSW /gen/setup/setup.ssw /quiet Once you have everything ready, in case you use zsh, you can define the following alias in your .zlogin (or .zshrc) file: alias sswidl = 'tcsh -c \"sswidl\"' This way you will be able to launch it without switching manually to tsch.","title":"SSWIDL"},{"location":"sswidl/#sswidl","text":"SolarSoft is a set of integrated software libraries, data bases, and system utilities which provide a common programming and data analysis environment for Solar Physics. It is primarily an IDL based system, although some instrument teams integrate executables written in other languages.","title":"SSWIDL"},{"location":"sswidl/#installation","text":"SSWIDL can be only used in csh/tcsh terminals, but we can configurate our terminal to launch without having to switch (see below). To install it, follow these instructions: SSWIDL_INSTALL . Choose, e.g., the following packages to install: chianti ontology aia iris hmi","title":"Installation"},{"location":"sswidl/#terminal-configuration","text":"Once installed, configurate your csh/tcsh terminal to use SSWIDL. In your home directory, in the .login file you need to define the system variable SSW as the location of your SSW installation, e.g.: setenv SSW \"/Users/yourname/ssw\" Then you need to define the SSW_INSTR with the list of instruments you have included in the installation. setenv SSW_INSTR \"chianti ontology aia iris hmi\" Finally, add the following line in your .login file: source $SSW /gen/setup/setup.ssw /quiet Once you have everything ready, in case you use zsh, you can define the following alias in your .zlogin (or .zshrc) file: alias sswidl = 'tcsh -c \"sswidl\"' This way you will be able to launch it without switching manually to tsch.","title":"Terminal configuration"},{"location":"terminal/","text":"Terminal \u00b6 This page contains my terminal configuration. Currently I work with zsh and therefore all the configuration is refered to it. .zshrc file \u00b6 ls options \u00b6 Setting shorcuts and colors in all the ls commands by default. alias ls = \"/bin/ls -FG\" alias la = \"ls -la\" alias ll = \"ls -lhrt\" export CLICOLOR = 1 export LSCOLORS = GxFxCxDxBxegedabagaced Other useful alias \u00b6 Setting no-window option as default for emacs: alias emacs = \"emacs -nw\" Setting colors as default option for grep: alias grep = \"grep --colour\" Checking empty folders: alias empty = \"find . -type d -empty\" #add -delete to remove the empty folders Since SSWIDL only works in tcsh , I do the following to avoid changing the terminal: alias sswidl = 'tcsh -c \"sswidl\"' Functions \u00b6 This a find function, so I can, e.g., f math_mpi to look for directories having * math_mpi * files avoiding moreover all the Permission denied messages in the output: f (){ echo \"find . -iname \\\"* $1 *\\\" 2>/dev/null\" find . -iname \"* $1 *\" 2 >/dev/null } Terminal appereance \u00b6 I prefer having my terminal as minimalist as possible, therefore I remove the username and host information in the terminal, to only show a ~ character. export PS1 = \"~ \" In order to know your current folder, on MacOS, you can go to Terminal preferences, Profiles, Windows, and enable the option \"Working directory or document\" and \"Path\". This way, the current folder is shown in the uppermost part of the terminal. Autoload and zstyle \u00b6 Enhancing the completion by assigning colors to the options, making them insensitive to lower-case/capital letters and enabling the TAB menu select: autoload -Uz compinit && compinit zmodload -i zsh/complist zstyle ':completion:*' list-colors '' zstyle ':completion:*' matcher-list 'm:{a-z}={A-Z}' zstyle ':completion:*' menu select","title":"Terminal"},{"location":"terminal/#terminal","text":"This page contains my terminal configuration. Currently I work with zsh and therefore all the configuration is refered to it.","title":"Terminal"},{"location":"terminal/#zshrc-file","text":"","title":".zshrc file"},{"location":"terminal/#ls-options","text":"Setting shorcuts and colors in all the ls commands by default. alias ls = \"/bin/ls -FG\" alias la = \"ls -la\" alias ll = \"ls -lhrt\" export CLICOLOR = 1 export LSCOLORS = GxFxCxDxBxegedabagaced","title":"ls options"},{"location":"terminal/#other-useful-alias","text":"Setting no-window option as default for emacs: alias emacs = \"emacs -nw\" Setting colors as default option for grep: alias grep = \"grep --colour\" Checking empty folders: alias empty = \"find . -type d -empty\" #add -delete to remove the empty folders Since SSWIDL only works in tcsh , I do the following to avoid changing the terminal: alias sswidl = 'tcsh -c \"sswidl\"'","title":"Other useful alias"},{"location":"terminal/#functions","text":"This a find function, so I can, e.g., f math_mpi to look for directories having * math_mpi * files avoiding moreover all the Permission denied messages in the output: f (){ echo \"find . -iname \\\"* $1 *\\\" 2>/dev/null\" find . -iname \"* $1 *\" 2 >/dev/null }","title":"Functions"},{"location":"terminal/#terminal-appereance","text":"I prefer having my terminal as minimalist as possible, therefore I remove the username and host information in the terminal, to only show a ~ character. export PS1 = \"~ \" In order to know your current folder, on MacOS, you can go to Terminal preferences, Profiles, Windows, and enable the option \"Working directory or document\" and \"Path\". This way, the current folder is shown in the uppermost part of the terminal.","title":"Terminal appereance"},{"location":"terminal/#autoload-and-zstyle","text":"Enhancing the completion by assigning colors to the options, making them insensitive to lower-case/capital letters and enabling the TAB menu select: autoload -Uz compinit && compinit zmodload -i zsh/complist zstyle ':completion:*' list-colors '' zstyle ':completion:*' matcher-list 'm:{a-z}={A-Z}' zstyle ':completion:*' menu select","title":"Autoload and zstyle"}]}