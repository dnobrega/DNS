{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DNS \u00b6 This is the documentation to the github repository DNS developed by Daniel N\u00f3brega Siverio. The aim of this repository and documentation is to providing guidance to people interested in the installation and configuration of the Bifrost code, useful Unix commands, as well as an IDL package for visualization of the data that requires Bifrost routines, among others.","title":"INTRODUCTION"},{"location":"#dns","text":"This is the documentation to the github repository DNS developed by Daniel N\u00f3brega Siverio. The aim of this repository and documentation is to providing guidance to people interested in the installation and configuration of the Bifrost code, useful Unix commands, as well as an IDL package for visualization of the data that requires Bifrost routines, among others.","title":"DNS"},{"location":"ALMA/","text":"ALMA \u00b6 ALMA home webpage: ALMA SSALMON home webpage: SSALMON Analyzing synthetic ALMA data from Bifrost simulations: int.h5 files. \u00b6 It is necessary to clone the Bifrost code and DNS package for the following instructions. To get a list of the existing synthetic files (int.h5) within a folder, type: f = alma_synthfiles() The synthetic files contain the following variables: list = [ 'Stokes_I' , 'Tau1' , 'Wavelength' ] For instance, to read Stokes_I , type: stokes_i = alma_readsynth(f( 0 ),Stokes_I) The units of the output variables are changed in the DNS routines. ; Stokes_I : Stokes Intensity in erg/cm^2 ; We convert it to temperature: ; Stokes_I * lambda^2/Kb ; Tau1 : Optical depth in cm ; We convert it to Mm ; Wavelength : Wavelength in Angstrom ; We convert it to mm This is the list of wavelengths and their correspondence with the different ALMA bands: 0 : (lambda): 5000.000 for debugging purposes (should looks like a photosphere) Band 3 // 3.2 -> 2.77 [mm] 1 : (lambda): 32586136.73913, (freq) 92000000000.00121, (to K) 3.845497e+14 2 : (lambda): 31892814.68085, (freq) 94000000000.00017, (to K) 3.683600e+14 3 : (lambda): 31228381.04167, (freq) 95999999999.99896, (to K) 3.531715e+14 4 : (lambda): 28826197.88462, (freq) 104000000000.00137, (to K) 3.009272e+14 5 : (lambda): 28282307.35849, (freq) 105999999999.99835, (to K) 2.896786e+14 6 : (lambda): 27758560.92593, (freq) 107999999999.99969, (to K) 2.790491e+14 Band 6 // 1.30 -> 1.20 [mm] 7 : (lambda): 13091373.71179, (freq) 229000000000.00690, (to K) 6.206649e+13 8 : (lambda): 12978028.48485, (freq) 231000000000.00870, (to K) 6.099639e+13 9 : (lambda): 12866629.09871, (freq) 233000000000.00815, (to K) 5.995374e+13 10 : (lambda): 12236426.85714, (freq) 244999999999.99716, (to K) 5.422455e+13 11 : (lambda): 12137346.47773, (freq) 246999999999.99585, (to K) 5.334998e+13 12 : (lambda): 12039857.75100, (freq) 249000000000.00040, (to K) 5.249639e+13 Band 7 // 0.88 -> 0.84 [mm] 13 : (lambda): 8853882.39811, (freq) 338599999999.99500, (to K) 2.838927e+13 14 : (lambda): 8801892.48385, (freq) 340600000000.00104, (to K) 2.805685e+13 15 : (lambda): 8750509.57385, (freq) 342600000000.00214, (to K) 2.773023e+13 16 : (lambda): 8550840.21677, (freq) 350600000000.01038, (to K) 2.647917e+13 17 : (lambda): 8502338.57062, (freq) 352600000000.01105, (to K) 2.617963e+13 18 : (lambda): 8454384.03835, (freq) 354600000000.00323, (to K) 2.588515e+13 Analyzing synthetic ALMA data from Bifrost simulations: model.h5 files. \u00b6 It is necessary to clone the Bifrost code and DNS package for the following instructions. To get a list of the existing model files (model.h5) that generated the ALMA synthetic files within a folder, type: g = alma_modelfiles() The model files contain the following variables: list = [ 'Pgas' , 'temperature' , 'dens' , 'dx' , 'dy' , 'z' ] The units of the output variables are as follows: ;Pgas : Gas pressure in CGS ;temperature : Temperature in K ;dens : Total density in CGS ;dx : X axis in cm. Converted to Mm. ;dy : Y axis in Mm. Converted to Mm. ;z : Z azis in Mm. Converted to Mm.","title":"ALMA"},{"location":"ALMA/#alma","text":"ALMA home webpage: ALMA SSALMON home webpage: SSALMON","title":"ALMA"},{"location":"ALMA/#analyzing-synthetic-alma-data-from-bifrost-simulations-inth5-files","text":"It is necessary to clone the Bifrost code and DNS package for the following instructions. To get a list of the existing synthetic files (int.h5) within a folder, type: f = alma_synthfiles() The synthetic files contain the following variables: list = [ 'Stokes_I' , 'Tau1' , 'Wavelength' ] For instance, to read Stokes_I , type: stokes_i = alma_readsynth(f( 0 ),Stokes_I) The units of the output variables are changed in the DNS routines. ; Stokes_I : Stokes Intensity in erg/cm^2 ; We convert it to temperature: ; Stokes_I * lambda^2/Kb ; Tau1 : Optical depth in cm ; We convert it to Mm ; Wavelength : Wavelength in Angstrom ; We convert it to mm This is the list of wavelengths and their correspondence with the different ALMA bands: 0 : (lambda): 5000.000 for debugging purposes (should looks like a photosphere) Band 3 // 3.2 -> 2.77 [mm] 1 : (lambda): 32586136.73913, (freq) 92000000000.00121, (to K) 3.845497e+14 2 : (lambda): 31892814.68085, (freq) 94000000000.00017, (to K) 3.683600e+14 3 : (lambda): 31228381.04167, (freq) 95999999999.99896, (to K) 3.531715e+14 4 : (lambda): 28826197.88462, (freq) 104000000000.00137, (to K) 3.009272e+14 5 : (lambda): 28282307.35849, (freq) 105999999999.99835, (to K) 2.896786e+14 6 : (lambda): 27758560.92593, (freq) 107999999999.99969, (to K) 2.790491e+14 Band 6 // 1.30 -> 1.20 [mm] 7 : (lambda): 13091373.71179, (freq) 229000000000.00690, (to K) 6.206649e+13 8 : (lambda): 12978028.48485, (freq) 231000000000.00870, (to K) 6.099639e+13 9 : (lambda): 12866629.09871, (freq) 233000000000.00815, (to K) 5.995374e+13 10 : (lambda): 12236426.85714, (freq) 244999999999.99716, (to K) 5.422455e+13 11 : (lambda): 12137346.47773, (freq) 246999999999.99585, (to K) 5.334998e+13 12 : (lambda): 12039857.75100, (freq) 249000000000.00040, (to K) 5.249639e+13 Band 7 // 0.88 -> 0.84 [mm] 13 : (lambda): 8853882.39811, (freq) 338599999999.99500, (to K) 2.838927e+13 14 : (lambda): 8801892.48385, (freq) 340600000000.00104, (to K) 2.805685e+13 15 : (lambda): 8750509.57385, (freq) 342600000000.00214, (to K) 2.773023e+13 16 : (lambda): 8550840.21677, (freq) 350600000000.01038, (to K) 2.647917e+13 17 : (lambda): 8502338.57062, (freq) 352600000000.01105, (to K) 2.617963e+13 18 : (lambda): 8454384.03835, (freq) 354600000000.00323, (to K) 2.588515e+13","title":"Analyzing synthetic ALMA data from Bifrost simulations: int.h5 files."},{"location":"ALMA/#analyzing-synthetic-alma-data-from-bifrost-simulations-modelh5-files","text":"It is necessary to clone the Bifrost code and DNS package for the following instructions. To get a list of the existing model files (model.h5) that generated the ALMA synthetic files within a folder, type: g = alma_modelfiles() The model files contain the following variables: list = [ 'Pgas' , 'temperature' , 'dens' , 'dx' , 'dy' , 'z' ] The units of the output variables are as follows: ;Pgas : Gas pressure in CGS ;temperature : Temperature in K ;dens : Total density in CGS ;dx : X axis in cm. Converted to Mm. ;dy : Y axis in Mm. Converted to Mm. ;z : Z azis in Mm. Converted to Mm.","title":"Analyzing synthetic ALMA data from Bifrost simulations: model.h5 files."},{"location":"IRIS/","text":"IRIS \u00b6 IRIS home webpage: IRIS IRIS Science Highlights: IRIS Higlights IRIS Event Search: IRIS Search IRIS Event Search + Other Telescopes/Observations: HEK Search Analyzing IRIS data \u00b6 Data Analysis Tutorials by Tiago Pereira: Data Analysis Tutorials IRIS2: IRIS2 A quick-start guide to work with IRIS Level2 data in Python: IRIS_LMSALPY Creating LVL3 data \u00b6 These are the steps to create LVL3 data to analyze, for instance, IRIS+SDO/AIA data. Download IRIS raster data + SDO data in the same folder. Open a SSWIDL session in that folder Write iris_xfiles and choose the folder with the data, choose one of the .fits and then create LVL3. After that, we make a list with the name of the IRIS and SDO files: f = iris_files() Finally, crispex, f(im), f(sp), sji = f(AIA), / win","title":"IRIS"},{"location":"IRIS/#iris","text":"IRIS home webpage: IRIS IRIS Science Highlights: IRIS Higlights IRIS Event Search: IRIS Search IRIS Event Search + Other Telescopes/Observations: HEK Search","title":"IRIS"},{"location":"IRIS/#analyzing-iris-data","text":"Data Analysis Tutorials by Tiago Pereira: Data Analysis Tutorials IRIS2: IRIS2 A quick-start guide to work with IRIS Level2 data in Python: IRIS_LMSALPY","title":"Analyzing IRIS data"},{"location":"IRIS/#creating-lvl3-data","text":"These are the steps to create LVL3 data to analyze, for instance, IRIS+SDO/AIA data. Download IRIS raster data + SDO data in the same folder. Open a SSWIDL session in that folder Write iris_xfiles and choose the folder with the data, choose one of the .fits and then create LVL3. After that, we make a list with the name of the IRIS and SDO files: f = iris_files() Finally, crispex, f(im), f(sp), sji = f(AIA), / win","title":"Creating LVL3 data"},{"location":"SDO/","text":"SDO \u00b6 Documentation in process...","title":"SDO"},{"location":"SDO/#sdo","text":"Documentation in process...","title":"SDO"},{"location":"SST/","text":"SST \u00b6 The Swedish 1-m Solar Telescope (SST) is a refracting solar telescope at Roque de los Muchachos Observatory, La Palma in the Canary Islands. The SST is capable of providing high-quality time series of spectrally resolved photospheric and chromospheric diagnostics that under excellent seeing conditions reach the diffraction limit of 0.1\" over the full arcmin^2 FOV. Furthermore, the versatile CRISP instrument can provide spectro-polarimetric data that enable measurement of the magnetic field topology. In addition, the tunable filter system CHROMIS, installed in 2016, can simultaneously provide narrowband filtergrams at several wavelengths in the core of the Ca II K line (Extracted from Rouppe et al. (2020) ). SST literature \u00b6 The SST telescope design and its main optical elements: Scharmer et al. 2003a . The SST adaptive optics system: Scharmer et al. 2003a . The CHROMospheric Imaging Spectrometer (CHROMIS): CHROMIS webpage The CRISP imaging spectropolarimeter Scharmer et al. 2008 Upgrades of optical components and instrumentation, as well as a thorough evaluation of optical performance: Scharmer et al. 2019 . Main links \u00b6 Overview of the observation conditions at the ORM in La Palma: Shahin's website SST wiki of RoCS: Wiki SST Observations Schedule: SST Schedule SST Data acquisitions: Data acquisitions Quicklook movies and images \u00b6 ITA has now a very basic web server with the purpose of providing simple access to files ment for temporary viewing - like quicklook movies. We can put the SST quicklook movies at /mn/stornext/d18/lapalma/quicklook/ which will then appear under http://tsih3.uio.no/lapalma/ . For example, the 14-Jun quicklook movies from the LMSAL campaign are now under http://tsih3.uio.no/lapalma/2020/2020-06-14/ which are linked from the Oslo SST wiki: https://wiki.uio.no/mn/astro/lapalma/index.php/Quicklook_June_2020#Sunday_14-Jun-2020 Script to combine CHROMIS quicklook movies and images: quickfile1 = 4861_+0 quickfile2 = -1371 image_format = .jpg movie_format = .mov for ii in $( ls -d */ ) ; do jj = \" ${ ii /// } \" cd $jj temp = * $quickfile1 * $image_format header = $( echo $temp | sed -e 's/\\(quick_..........\\).*/\\1/' ) \"_\" image = $header \" ${ jj //: } \" $image_format movie = $header \" ${ jj //: } \" $movie_format echo $image echo $movie ysize = $( ffprobe -v error -select_streams v:0 -show_entries stream = height -of csv = s = x:p = 0 * $quickfile1 * $image_format ) echo $ysize ffmpeg -i * $quickfile1 * $image_format -i \\ * $quickfile2 * $image_format \\ -q:v 1 -filter_complex vstack = inputs = 2 $image -hide_banner ffmpeg -i * $quickfile1 * $movie_format -i \\ * $quickfile2 * $movie_format \\ -filter_complex vstack = inputs = 2 \\ $movie -hide_banner cd .. done Script to combine CRISP quicklook movies and images: quickfile1 = 6563_+0 quickfile2 = 8542_+0 quickfile3 = -1680 image_format = .jpg movie_format = .mov for ii in $( ls -d */ ) ; do jj = \" ${ ii /// } \" cd $jj temp = * $quickfile1 * $image_format header = $( echo $temp | sed -e 's/\\(quick_..........\\).*/\\1/' ) \"_\" image = $header \" ${ jj //: } \" $image_format movie = $header \" ${ jj //: } \" $movie_format ffmpeg -i * $quickfile1 * $image_format -i \\ * $quickfile2 * $image_format -i \\ * $quickfile3 * $image_format \\ -q:v 1 -filter_complex hstack = inputs = 3 $image -hide_banner ffmpeg -i * $quickfile1 * $movie_format -i \\ * $quickfile2 * $movie_format -i \\ * $quickfile3 * $movie_format \\ -filter_complex hstack = inputs = 3 $movie -hide_banner cd .. done Extracting IRIS SAA times for the SST log \u00b6 This scripts extracts the IRIS SAA times and copy them in your clipboard on MacOs systems. curl -s $1 | grep SAAI | awk '{print $2}' | sed -e 's/\\(:..\\).*/\\1/' > saai.txt curl -s $1 | grep SAAO | awk '{print $2}' | sed 's/\\(:..\\).*/\\1 IRIS in SAA <br\\>/' > saao.txt paste -d \"~\" saai.txt saao.txt | sed 's/~/ - /' | pbcopy -selection c rm saai.txt rm saao.txt The input of the script for a given day can be found within TIM in the following webpage: IRIS_SAA For Linux, if you have X installed you may define an equivalent to pbcopy from MacOS in this way : alias pbcopy = 'xsel --clipboard --input' alias pbpaste = 'xsel --clipboard --output' or with xclip: alias pbcopy = 'xclip -selection clipboard' alias pbpaste = 'xclip -selection clipboard -o'","title":"SST"},{"location":"SST/#sst","text":"The Swedish 1-m Solar Telescope (SST) is a refracting solar telescope at Roque de los Muchachos Observatory, La Palma in the Canary Islands. The SST is capable of providing high-quality time series of spectrally resolved photospheric and chromospheric diagnostics that under excellent seeing conditions reach the diffraction limit of 0.1\" over the full arcmin^2 FOV. Furthermore, the versatile CRISP instrument can provide spectro-polarimetric data that enable measurement of the magnetic field topology. In addition, the tunable filter system CHROMIS, installed in 2016, can simultaneously provide narrowband filtergrams at several wavelengths in the core of the Ca II K line (Extracted from Rouppe et al. (2020) ).","title":"SST"},{"location":"SST/#sst-literature","text":"The SST telescope design and its main optical elements: Scharmer et al. 2003a . The SST adaptive optics system: Scharmer et al. 2003a . The CHROMospheric Imaging Spectrometer (CHROMIS): CHROMIS webpage The CRISP imaging spectropolarimeter Scharmer et al. 2008 Upgrades of optical components and instrumentation, as well as a thorough evaluation of optical performance: Scharmer et al. 2019 .","title":"SST literature"},{"location":"SST/#main-links","text":"Overview of the observation conditions at the ORM in La Palma: Shahin's website SST wiki of RoCS: Wiki SST Observations Schedule: SST Schedule SST Data acquisitions: Data acquisitions","title":"Main links"},{"location":"SST/#quicklook-movies-and-images","text":"ITA has now a very basic web server with the purpose of providing simple access to files ment for temporary viewing - like quicklook movies. We can put the SST quicklook movies at /mn/stornext/d18/lapalma/quicklook/ which will then appear under http://tsih3.uio.no/lapalma/ . For example, the 14-Jun quicklook movies from the LMSAL campaign are now under http://tsih3.uio.no/lapalma/2020/2020-06-14/ which are linked from the Oslo SST wiki: https://wiki.uio.no/mn/astro/lapalma/index.php/Quicklook_June_2020#Sunday_14-Jun-2020 Script to combine CHROMIS quicklook movies and images: quickfile1 = 4861_+0 quickfile2 = -1371 image_format = .jpg movie_format = .mov for ii in $( ls -d */ ) ; do jj = \" ${ ii /// } \" cd $jj temp = * $quickfile1 * $image_format header = $( echo $temp | sed -e 's/\\(quick_..........\\).*/\\1/' ) \"_\" image = $header \" ${ jj //: } \" $image_format movie = $header \" ${ jj //: } \" $movie_format echo $image echo $movie ysize = $( ffprobe -v error -select_streams v:0 -show_entries stream = height -of csv = s = x:p = 0 * $quickfile1 * $image_format ) echo $ysize ffmpeg -i * $quickfile1 * $image_format -i \\ * $quickfile2 * $image_format \\ -q:v 1 -filter_complex vstack = inputs = 2 $image -hide_banner ffmpeg -i * $quickfile1 * $movie_format -i \\ * $quickfile2 * $movie_format \\ -filter_complex vstack = inputs = 2 \\ $movie -hide_banner cd .. done Script to combine CRISP quicklook movies and images: quickfile1 = 6563_+0 quickfile2 = 8542_+0 quickfile3 = -1680 image_format = .jpg movie_format = .mov for ii in $( ls -d */ ) ; do jj = \" ${ ii /// } \" cd $jj temp = * $quickfile1 * $image_format header = $( echo $temp | sed -e 's/\\(quick_..........\\).*/\\1/' ) \"_\" image = $header \" ${ jj //: } \" $image_format movie = $header \" ${ jj //: } \" $movie_format ffmpeg -i * $quickfile1 * $image_format -i \\ * $quickfile2 * $image_format -i \\ * $quickfile3 * $image_format \\ -q:v 1 -filter_complex hstack = inputs = 3 $image -hide_banner ffmpeg -i * $quickfile1 * $movie_format -i \\ * $quickfile2 * $movie_format -i \\ * $quickfile3 * $movie_format \\ -filter_complex hstack = inputs = 3 $movie -hide_banner cd .. done","title":"Quicklook movies and images"},{"location":"SST/#extracting-iris-saa-times-for-the-sst-log","text":"This scripts extracts the IRIS SAA times and copy them in your clipboard on MacOs systems. curl -s $1 | grep SAAI | awk '{print $2}' | sed -e 's/\\(:..\\).*/\\1/' > saai.txt curl -s $1 | grep SAAO | awk '{print $2}' | sed 's/\\(:..\\).*/\\1 IRIS in SAA <br\\>/' > saao.txt paste -d \"~\" saai.txt saao.txt | sed 's/~/ - /' | pbcopy -selection c rm saai.txt rm saao.txt The input of the script for a given day can be found within TIM in the following webpage: IRIS_SAA For Linux, if you have X installed you may define an equivalent to pbcopy from MacOS in this way : alias pbcopy = 'xsel --clipboard --input' alias pbpaste = 'xsel --clipboard --output' or with xclip: alias pbcopy = 'xclip -selection clipboard' alias pbpaste = 'xclip -selection clipboard -o'","title":"Extracting IRIS SAA times for the SST log"},{"location":"about/","text":"Daniel N\u00f3brega-Siverio \u00b6 About me \u00b6 Postdoctoral researcher at Rosseland Centre for Solar Physics (RoCS) since the 1st of Agust 2018. Papers \u00b6 9 papers in refereed journals. 107 citations. H-index: 5. Ion\u2500neutral Interactions and Nonequilibrium Ionization in the Solar Chromosphere. Mart\u00ednez-Sykora et al. (2020) Nonequilibrium ionization and ambipolar diffusion in solar magnetic flux emergence processes. N\u00f3brega-Siverio et al. (2020) Ellerman bombs and UV bursts: reconnection at different atmospheric layers. Ortiz et al. (2020) Signatures of Magnetic Reconnection at the Footpoints of Fan-shaped Jets on a Light Bridge Driven by Photospheric Convective Motions. Bai et al. (2019) On the Importance of the Nonequilibrium Ionization of Si IV and O IV and the Line of Sight in Solar Surges. N\u00f3brega-Siverio et al. (2018) Intermittent Reconnection and Plasmoids in UV Bursts in the Low Solar Atmosphere. Rouppe van der Voort et al. (2017) Surges and Si IV Bursts in the Solar Atmosphere: Understanding IRIS and SST Observations through RMHD Experiments. N\u00f3brega-Siverio et al. (2017) Two-dimensional Radiative Magnetohydrodynamic Simulations of Partial Ionization in the Chromosphere. II. Dynamics and Energetics of the Low Solar Atmosphere. Mart\u00ednez-Sykora et al. (2017) The Cool Surge Following Flux Emergence in a Radiation-MHD Experiment. N\u00f3brega-Siverio et al. (2016) Invited talks \u00b6 Modeling UV bursts. 10th IRIS meeting. 4-8 November 2019 (Bangalore, India). Education \u00b6 2013 \u2013 2018 : Doctorate. Thesis: Eruptive phenomena in the solar atmosphere: radiation-MHD modeling and code development. - Supervisor: Prof. Fernando Moreno Insertis - Co-supervisor: Dr. Juan Mart\u00ednez Sykora - Instituto de Astrof\u00edsica de Canarias (IAC) - Universidad de La Laguna (ULL) 2012 \u2013 2013 : Master's Degree in Astrophysics. Master's Thesis: Magnetic flux emergence from the interior to the solar corona: reconnection, instabilities and jets. - Supervisor: Prof. Fernando Moreno Insertis - Co-supervisor: Dr. Juan Mart\u00ednez Sykora - Instituto de Astrof\u00edsica de Canarias (IAC) - Universidad de La Laguna (ULL) 2007 \u2013 2012 : Graduate in Physics. Degree's Thesis: Use of 3D numerical experiments about the solar plasma dynamics. - Supervisor: Prof. Fernando Moreno Insertis - Universidad de La Laguna (ULL)","title":"ABOUT"},{"location":"about/#daniel-nobrega-siverio","text":"","title":"Daniel N\u00f3brega-Siverio"},{"location":"about/#about-me","text":"Postdoctoral researcher at Rosseland Centre for Solar Physics (RoCS) since the 1st of Agust 2018.","title":"About me"},{"location":"about/#papers","text":"9 papers in refereed journals. 107 citations. H-index: 5. Ion\u2500neutral Interactions and Nonequilibrium Ionization in the Solar Chromosphere. Mart\u00ednez-Sykora et al. (2020) Nonequilibrium ionization and ambipolar diffusion in solar magnetic flux emergence processes. N\u00f3brega-Siverio et al. (2020) Ellerman bombs and UV bursts: reconnection at different atmospheric layers. Ortiz et al. (2020) Signatures of Magnetic Reconnection at the Footpoints of Fan-shaped Jets on a Light Bridge Driven by Photospheric Convective Motions. Bai et al. (2019) On the Importance of the Nonequilibrium Ionization of Si IV and O IV and the Line of Sight in Solar Surges. N\u00f3brega-Siverio et al. (2018) Intermittent Reconnection and Plasmoids in UV Bursts in the Low Solar Atmosphere. Rouppe van der Voort et al. (2017) Surges and Si IV Bursts in the Solar Atmosphere: Understanding IRIS and SST Observations through RMHD Experiments. N\u00f3brega-Siverio et al. (2017) Two-dimensional Radiative Magnetohydrodynamic Simulations of Partial Ionization in the Chromosphere. II. Dynamics and Energetics of the Low Solar Atmosphere. Mart\u00ednez-Sykora et al. (2017) The Cool Surge Following Flux Emergence in a Radiation-MHD Experiment. N\u00f3brega-Siverio et al. (2016)","title":"Papers"},{"location":"about/#invited-talks","text":"Modeling UV bursts. 10th IRIS meeting. 4-8 November 2019 (Bangalore, India).","title":"Invited talks"},{"location":"about/#education","text":"2013 \u2013 2018 : Doctorate. Thesis: Eruptive phenomena in the solar atmosphere: radiation-MHD modeling and code development. - Supervisor: Prof. Fernando Moreno Insertis - Co-supervisor: Dr. Juan Mart\u00ednez Sykora - Instituto de Astrof\u00edsica de Canarias (IAC) - Universidad de La Laguna (ULL) 2012 \u2013 2013 : Master's Degree in Astrophysics. Master's Thesis: Magnetic flux emergence from the interior to the solar corona: reconnection, instabilities and jets. - Supervisor: Prof. Fernando Moreno Insertis - Co-supervisor: Dr. Juan Mart\u00ednez Sykora - Instituto de Astrof\u00edsica de Canarias (IAC) - Universidad de La Laguna (ULL) 2007 \u2013 2012 : Graduate in Physics. Degree's Thesis: Use of 3D numerical experiments about the solar plasma dynamics. - Supervisor: Prof. Fernando Moreno Insertis - Universidad de La Laguna (ULL)","title":"Education"},{"location":"bifrost/","text":"Bifrost \u00b6 Bifrost literature \u00b6 The paper explaing the code can be found in Gudiksen et al. (2011) Other important papers to understand the Bifrost modules are: Equation of state: Gustafsson et al. (1975) Radiative transfer solver with coherent scattering: Hayek et al. (2010) Nonequilibrium ionization of Hydrogen: Leenaarts et al. (2011) Radiative transfer in the chromosphere: Carlsson and Leenaarts (2012) Generalized Ohm's Law: Mart\u00ednez-Sykora et al. (2012) Nonequilibrium ionization of optically thin ions : Olluri et al. (2013) Nonequilibrium ionization of Helium: Golding et al. (2016) Lagrangian Tracing module: Leenaarts (2018) New ambipolar difussion module: N\u00f3brega-Siverio et al. (2020) Getting Bifrost \u00b6 Bifrost is located on github. The repository is private, meaning you should be logged in with your github username to see it at: Bifrost repository To get started with the new repository, you'll need to have git (pre-installed in most machines) and configure it to use your name and email address you registered with github, by doing something like: git config --global user.name \"Daniel Nobrega\" git config --global user.email dnobrega@example.com You can clone the repository through HTTPS like this: git clone https://username@github.com/ITA-Solar/Bifrost.git replacing \"username\" with your github username. Terminal configuration \u00b6 It is useful to create (or modify) your .login file in your home directory to add the following system variable. In case of working with tcsh: setenv BIFROST \"/folder/Bifrost\" where folder is the location where you have cloned the Bifrost repository. You can also add an alias so you can go the Bifrost folder easily. In case of working with tcsh: alias bifrost \"cd /folder/Bifrost/\" where folder is again the location where you have cloned the Bifrost repository. Bifrost documentation \u00b6 For information about how to run Bifrost, check the documentation in Bifrost","title":"BIFROST"},{"location":"bifrost/#bifrost","text":"","title":"Bifrost"},{"location":"bifrost/#bifrost-literature","text":"The paper explaing the code can be found in Gudiksen et al. (2011) Other important papers to understand the Bifrost modules are: Equation of state: Gustafsson et al. (1975) Radiative transfer solver with coherent scattering: Hayek et al. (2010) Nonequilibrium ionization of Hydrogen: Leenaarts et al. (2011) Radiative transfer in the chromosphere: Carlsson and Leenaarts (2012) Generalized Ohm's Law: Mart\u00ednez-Sykora et al. (2012) Nonequilibrium ionization of optically thin ions : Olluri et al. (2013) Nonequilibrium ionization of Helium: Golding et al. (2016) Lagrangian Tracing module: Leenaarts (2018) New ambipolar difussion module: N\u00f3brega-Siverio et al. (2020)","title":"Bifrost literature"},{"location":"bifrost/#getting-bifrost","text":"Bifrost is located on github. The repository is private, meaning you should be logged in with your github username to see it at: Bifrost repository To get started with the new repository, you'll need to have git (pre-installed in most machines) and configure it to use your name and email address you registered with github, by doing something like: git config --global user.name \"Daniel Nobrega\" git config --global user.email dnobrega@example.com You can clone the repository through HTTPS like this: git clone https://username@github.com/ITA-Solar/Bifrost.git replacing \"username\" with your github username.","title":"Getting Bifrost"},{"location":"bifrost/#terminal-configuration","text":"It is useful to create (or modify) your .login file in your home directory to add the following system variable. In case of working with tcsh: setenv BIFROST \"/folder/Bifrost\" where folder is the location where you have cloned the Bifrost repository. You can also add an alias so you can go the Bifrost folder easily. In case of working with tcsh: alias bifrost \"cd /folder/Bifrost/\" where folder is again the location where you have cloned the Bifrost repository.","title":"Terminal configuration"},{"location":"bifrost/#bifrost-documentation","text":"For information about how to run Bifrost, check the documentation in Bifrost","title":"Bifrost documentation"},{"location":"dns/","text":"DNS \u00b6 Getting DNS package \u00b6 You can clone the repository through HTTPS like this: git clone https://username@github.com/dnobrega/DNS.git replacing \"username\" with your github username. Terminal configuration \u00b6 It is necessary to modify your .login file in your home directory to add the following system variables. In case of working with tcsh: setenv DNS \"/folder/DNS\" setenv IDL_DNS $DNS \"/dnspro\" where folder is in this case the location where you have cloned the DNS package. Then you need to add IDL_DNS path to the IDL_PATH . You should have something like this in case of using tcsh and Mac: setenv IDL_PATH \"/Applications/exelis/idl85/bin\"\":+\" $BIFROST_IDL \":+\" $IDL_DNS Finally, you need to define a variable called DNS_PROJECTS with the default location where you want to save the plots and movies you are going to create with the DNS package, e.g., setenv DNS_PROJECTS \"~/dns_plots\" Obviously, you will also need to create that folder. Within DNS_PROJECTS , other folders will be automatically created with the name of the simulation when you save a image or movie. Using DNS routines \u00b6 Within a folder with a Bifrost experiment, run SSWIDL . The first plot we are going to create is a density plot: dns_plot, \"r\" ,snapt = 0 where you have to modify snapt variable with the number of snapshot you want to plot. In case of a 3D run, by default it will show the \"XZ\" plane along the whole Y-direction. You can modify which slices you want to show, e.g., dns_plot, \"r\" ,snapt = 0 , iy0 = 10 , iyf = 100 , iystep = 2 will show from index 10 to index 100 in Y-direction each two indexes. In case you want a specific slice in Y-direction, use iyt , e..g, dns_plot, \"r\" ,snapt = 0 , iyt = 300 , / png In this case we have also added the png flag to save the image as a .png file in DNS_PROJECTS folder. You can also plot animations moving in time as follows: dns_plot, \"r\" ,snap0 = 0 , snapf = 500 , step = 10 , iyt = 300 That will show the XZ plane of the simulation in the index 300 of the Y-direction from snapshot 0 to snapshot 500 each 10 snapshots. You can save the previous animation, writing dns_plot, \"r\" ,snap0 = 0 , snapf = 500 , step = 10 , iyt = 300 , / movie, / setplot That will create a movie in your DNS_PROJECTS folder. The setplot flag is to create the movie using the Z buffer device. In 3D experiments you can plot different planes, for example, dns_plot, \"r\" ,snapt = 100 , dim = \"yz\" , ixstep = 10 which will show the YZ plane each 10 indexes in X-direction. You can do the same for XY, dns_plot, \"r\" ,snapt = 100 , dim = \"xy\" , izstep = 10 You can customize your window size, thickness, colors, position of the plot... For instance, dns_plot, \"r\" ,snapt = 100 , dim = \"xy\" , izstep = 10 , xsize = 1200 , ysize = 600 , load = 39 , position = [ 0.14 , 0.08 , 0.92 , 0.74 ] Once you are happy with your plot setup, you can save it, so you will not need to write all the commands again. To do that, use dns_plot, \"r\" ,snapt = 100 , dim = \"xy\" , izstep = 10 , xsize = 1200 , ysize = 600 , load = 39 , position = [ 0.14 , 0.08 , 0.92 , 0.74 ], / save_dns_confi That will create a file in your current directory called dns_confi.sav with the plot parameters you have defined. Concerning the variables you can plot with DNS package, check dnspro/var folder. There you will see a list of routines containg each one a variable. For example, for the density, you will see a file called dnsvar_r.pro PRO dnsvar_r, d, name, snaps, swap, var, $ var_title = var_title, var_range = var_range, var_log = var_log, $ info = info IF KEYWORD_SET (info) THEN BEGIN message , 'Density: rho (g/cm^3)' , / info RETURN ENDIF ELSE BEGIN IF n_params () LT 5 THEN BEGIN message , 'dnsvar_r, d, name, snaps, swap, var' $ + 'var_title=var_title, var_range=var_range, var_log=var_log' , / info RETURN ENDIF UNITS, units var = d -> getvar(name,snaps,swap = swap) * units.ur var_title = '!4q!3 (g cm!u-3!n)' var_range = [ 1.d-15 , 1.d-11 ] var_log = 1 ENDELSE END You can create all the variables following this format. So far, the list only includes the most fundamental variables. If you need help with the meaning of each variable, in the IDL prompt you can type, e.g., dnsvar_modb, / info which will show the information about the variable of that routine, in this case, % DNSVAR_MODB: Module of the magnetic field: B ( G )","title":"DNS"},{"location":"dns/#dns","text":"","title":"DNS"},{"location":"dns/#getting-dns-package","text":"You can clone the repository through HTTPS like this: git clone https://username@github.com/dnobrega/DNS.git replacing \"username\" with your github username.","title":"Getting DNS package"},{"location":"dns/#terminal-configuration","text":"It is necessary to modify your .login file in your home directory to add the following system variables. In case of working with tcsh: setenv DNS \"/folder/DNS\" setenv IDL_DNS $DNS \"/dnspro\" where folder is in this case the location where you have cloned the DNS package. Then you need to add IDL_DNS path to the IDL_PATH . You should have something like this in case of using tcsh and Mac: setenv IDL_PATH \"/Applications/exelis/idl85/bin\"\":+\" $BIFROST_IDL \":+\" $IDL_DNS Finally, you need to define a variable called DNS_PROJECTS with the default location where you want to save the plots and movies you are going to create with the DNS package, e.g., setenv DNS_PROJECTS \"~/dns_plots\" Obviously, you will also need to create that folder. Within DNS_PROJECTS , other folders will be automatically created with the name of the simulation when you save a image or movie.","title":"Terminal configuration"},{"location":"dns/#using-dns-routines","text":"Within a folder with a Bifrost experiment, run SSWIDL . The first plot we are going to create is a density plot: dns_plot, \"r\" ,snapt = 0 where you have to modify snapt variable with the number of snapshot you want to plot. In case of a 3D run, by default it will show the \"XZ\" plane along the whole Y-direction. You can modify which slices you want to show, e.g., dns_plot, \"r\" ,snapt = 0 , iy0 = 10 , iyf = 100 , iystep = 2 will show from index 10 to index 100 in Y-direction each two indexes. In case you want a specific slice in Y-direction, use iyt , e..g, dns_plot, \"r\" ,snapt = 0 , iyt = 300 , / png In this case we have also added the png flag to save the image as a .png file in DNS_PROJECTS folder. You can also plot animations moving in time as follows: dns_plot, \"r\" ,snap0 = 0 , snapf = 500 , step = 10 , iyt = 300 That will show the XZ plane of the simulation in the index 300 of the Y-direction from snapshot 0 to snapshot 500 each 10 snapshots. You can save the previous animation, writing dns_plot, \"r\" ,snap0 = 0 , snapf = 500 , step = 10 , iyt = 300 , / movie, / setplot That will create a movie in your DNS_PROJECTS folder. The setplot flag is to create the movie using the Z buffer device. In 3D experiments you can plot different planes, for example, dns_plot, \"r\" ,snapt = 100 , dim = \"yz\" , ixstep = 10 which will show the YZ plane each 10 indexes in X-direction. You can do the same for XY, dns_plot, \"r\" ,snapt = 100 , dim = \"xy\" , izstep = 10 You can customize your window size, thickness, colors, position of the plot... For instance, dns_plot, \"r\" ,snapt = 100 , dim = \"xy\" , izstep = 10 , xsize = 1200 , ysize = 600 , load = 39 , position = [ 0.14 , 0.08 , 0.92 , 0.74 ] Once you are happy with your plot setup, you can save it, so you will not need to write all the commands again. To do that, use dns_plot, \"r\" ,snapt = 100 , dim = \"xy\" , izstep = 10 , xsize = 1200 , ysize = 600 , load = 39 , position = [ 0.14 , 0.08 , 0.92 , 0.74 ], / save_dns_confi That will create a file in your current directory called dns_confi.sav with the plot parameters you have defined. Concerning the variables you can plot with DNS package, check dnspro/var folder. There you will see a list of routines containg each one a variable. For example, for the density, you will see a file called dnsvar_r.pro PRO dnsvar_r, d, name, snaps, swap, var, $ var_title = var_title, var_range = var_range, var_log = var_log, $ info = info IF KEYWORD_SET (info) THEN BEGIN message , 'Density: rho (g/cm^3)' , / info RETURN ENDIF ELSE BEGIN IF n_params () LT 5 THEN BEGIN message , 'dnsvar_r, d, name, snaps, swap, var' $ + 'var_title=var_title, var_range=var_range, var_log=var_log' , / info RETURN ENDIF UNITS, units var = d -> getvar(name,snaps,swap = swap) * units.ur var_title = '!4q!3 (g cm!u-3!n)' var_range = [ 1.d-15 , 1.d-11 ] var_log = 1 ENDELSE END You can create all the variables following this format. So far, the list only includes the most fundamental variables. If you need help with the meaning of each variable, in the IDL prompt you can type, e.g., dnsvar_modb, / info which will show the information about the variable of that routine, in this case, % DNSVAR_MODB: Module of the magnetic field: B ( G )","title":"Using DNS routines"},{"location":"idl/","text":"IDL in Bifrost \u00b6 First steps \u00b6 In your home directory, check your .login file to see if you have defined the following variables: IDL_DIR and IDL_PATH . In case of using Mac and tcsh, you should have something like this: setenv IDL_PATH \"/Applications/exelis/idl85/bin\" setenv IDL_DIR \"/Applications/exelis/idl85/\" including the IDL_PATH in your PATH : setenv PATH $PATH \":\" $IDL_PATH In addition to that, you need to have installed Solar Soft IDL (SSWIDL). Check the documentation in SSWIDL Terminal configuration to use the IDL routines of Bifrost \u00b6 Modify your .login file to add the following system variables. In case of working with tcsh: setenv BIFROST_IDL $BIFROST \"/IDL\" where BIFROST is a system variable for your Bifrost repository (see Bifrost section). Then, modifiy your IDL_PATH to the the Bifrost IDL folder: setenv IDL_PATH \"/Applications/exelis/idl85/bin\"\":+\" $BIFROST_IDL It is also necessary to define a system variable called OSC_CSTAGGER , which depends on your operative system. If you use a Linux system: setenv OSC_CSTAGGER $BIFROST_IDL \"/cstagger/linux\" In case of a intelmac: setenv OSC_CSTAGGER $BIFROST_IDL \"/cstagger/intelmac\" Stagger configuration \u00b6 Next step is to go to your stagger folder, typing in your terminal cd $OSC_CSTAGGER and then make That would create the following six files: cstagger.pro cstagger.c cstagger.o init_stagger.o inverse.o cstagger.so which are necessary for stagger operations. IDL startup \u00b6 After all this steps, create a IDL startup file. This file is going to be executed automatically each time IDL is started. For example, you can create it in your IDLWorkspace and then add a similar line in your .login file (in case of using tcsh) with the location: setenv IDL_STARTUP \"/Users/yourname/IDLWorkspace85/startup.pro\" Edit the startup.pro file to add the following line .r $OSC_CSTAGGER / cstagger whici will compile the Stagger routines each time you execute IDL. With all the information above, you should be able to use the IDL routines of Bifrost without any problem. I also have the following useful lines in startup.pro br_select_idlparam, idlparam d = obj_new ( 'br_data' , idlparam) br_getsnapind, idlparam, snaps PRINT , '%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%' PRINT , ' Project : ' , idlparam, ' ' , strtrim ( string ( min (snaps)), 2 ), '-' , strtrim ( string ( max (snaps)), 2 ) PRINT , '%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%' PRINT , ' so everytime I run IDL within a folder containing a numerical experiment carried out with Bifrost, I get the object to load Bifrost variables ( d ), the name of the simulation ( idlparam ) and all the snapshots I have in that folder ( snaps ). Then I print on the screen some of that information.","title":"IDL"},{"location":"idl/#idl-in-bifrost","text":"","title":"IDL in Bifrost"},{"location":"idl/#first-steps","text":"In your home directory, check your .login file to see if you have defined the following variables: IDL_DIR and IDL_PATH . In case of using Mac and tcsh, you should have something like this: setenv IDL_PATH \"/Applications/exelis/idl85/bin\" setenv IDL_DIR \"/Applications/exelis/idl85/\" including the IDL_PATH in your PATH : setenv PATH $PATH \":\" $IDL_PATH In addition to that, you need to have installed Solar Soft IDL (SSWIDL). Check the documentation in SSWIDL","title":"First steps"},{"location":"idl/#terminal-configuration-to-use-the-idl-routines-of-bifrost","text":"Modify your .login file to add the following system variables. In case of working with tcsh: setenv BIFROST_IDL $BIFROST \"/IDL\" where BIFROST is a system variable for your Bifrost repository (see Bifrost section). Then, modifiy your IDL_PATH to the the Bifrost IDL folder: setenv IDL_PATH \"/Applications/exelis/idl85/bin\"\":+\" $BIFROST_IDL It is also necessary to define a system variable called OSC_CSTAGGER , which depends on your operative system. If you use a Linux system: setenv OSC_CSTAGGER $BIFROST_IDL \"/cstagger/linux\" In case of a intelmac: setenv OSC_CSTAGGER $BIFROST_IDL \"/cstagger/intelmac\"","title":"Terminal configuration to use the IDL routines of Bifrost"},{"location":"idl/#stagger-configuration","text":"Next step is to go to your stagger folder, typing in your terminal cd $OSC_CSTAGGER and then make That would create the following six files: cstagger.pro cstagger.c cstagger.o init_stagger.o inverse.o cstagger.so which are necessary for stagger operations.","title":"Stagger configuration"},{"location":"idl/#idl-startup","text":"After all this steps, create a IDL startup file. This file is going to be executed automatically each time IDL is started. For example, you can create it in your IDLWorkspace and then add a similar line in your .login file (in case of using tcsh) with the location: setenv IDL_STARTUP \"/Users/yourname/IDLWorkspace85/startup.pro\" Edit the startup.pro file to add the following line .r $OSC_CSTAGGER / cstagger whici will compile the Stagger routines each time you execute IDL. With all the information above, you should be able to use the IDL routines of Bifrost without any problem. I also have the following useful lines in startup.pro br_select_idlparam, idlparam d = obj_new ( 'br_data' , idlparam) br_getsnapind, idlparam, snaps PRINT , '%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%' PRINT , ' Project : ' , idlparam, ' ' , strtrim ( string ( min (snaps)), 2 ), '-' , strtrim ( string ( max (snaps)), 2 ) PRINT , '%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%' PRINT , ' so everytime I run IDL within a folder containing a numerical experiment carried out with Bifrost, I get the object to load Bifrost variables ( d ), the name of the simulation ( idlparam ) and all the snapshots I have in that folder ( snaps ). Then I print on the screen some of that information.","title":"IDL startup"},{"location":"python/","text":"Python \u00b6 Here you can find some useful links to install Anaconda and interesting Python libraries as well as specific tutorials. Anaconda \u00b6 Anaconda is a package manager, an environment manager, a Python/R data science distribution, and a collection of over 7,500+ open-source packages. See the instructions for the installation here: Anaconda IRISpy \u00b6 Python library to analyze IRIS Level 2 data: IRISpy AIApy \u00b6 AIApy is a Python package for analyzing data from the Atmospheric Imaging Assembly (AIA) instrument onboard the Solar Dynamics Observatory spacecraft. It includes software for converting AIA images from level 1 to level 1.5, point spread function deconvolution, and computing the wavelength and temperature response functions for the EUV channels: AIApy SunPy \u00b6 SunPy is an open-source Python library for Solar Physics data analysis and visualization: Sunpy scikit-learn \u00b6 Machine learning library in Python: scikit-learn SciPy meeting \u00b6 The annual SciPy Conferences allows participants from academic, commercial, and governmental organizations to: - showcase their latest Scientific Python projects, - learn from skilled users and developers, and - collaborate on code development. The conferences generally consists of multiple days of tutorials followed by two-three days of presentations, and concludes with 1-2 days developer sprints on projects of interest to the attendees. https://conference.scipy.org/ Some tutorials from SciPy meeting \u00b6 Dask (multi-core execution on larger-than-memory datasets): Dask tutorial Deep learning from scratch with pytorch: Deep learning tutorial Jupyter widget ecosystem: Widget tutorial","title":"PYTHON"},{"location":"python/#python","text":"Here you can find some useful links to install Anaconda and interesting Python libraries as well as specific tutorials.","title":"Python"},{"location":"python/#anaconda","text":"Anaconda is a package manager, an environment manager, a Python/R data science distribution, and a collection of over 7,500+ open-source packages. See the instructions for the installation here: Anaconda","title":"Anaconda"},{"location":"python/#irispy","text":"Python library to analyze IRIS Level 2 data: IRISpy","title":"IRISpy"},{"location":"python/#aiapy","text":"AIApy is a Python package for analyzing data from the Atmospheric Imaging Assembly (AIA) instrument onboard the Solar Dynamics Observatory spacecraft. It includes software for converting AIA images from level 1 to level 1.5, point spread function deconvolution, and computing the wavelength and temperature response functions for the EUV channels: AIApy","title":"AIApy"},{"location":"python/#sunpy","text":"SunPy is an open-source Python library for Solar Physics data analysis and visualization: Sunpy","title":"SunPy"},{"location":"python/#scikit-learn","text":"Machine learning library in Python: scikit-learn","title":"scikit-learn"},{"location":"python/#scipy-meeting","text":"The annual SciPy Conferences allows participants from academic, commercial, and governmental organizations to: - showcase their latest Scientific Python projects, - learn from skilled users and developers, and - collaborate on code development. The conferences generally consists of multiple days of tutorials followed by two-three days of presentations, and concludes with 1-2 days developer sprints on projects of interest to the attendees. https://conference.scipy.org/","title":"SciPy meeting"},{"location":"python/#some-tutorials-from-scipy-meeting","text":"Dask (multi-core execution on larger-than-memory datasets): Dask tutorial Deep learning from scratch with pytorch: Deep learning tutorial Jupyter widget ecosystem: Widget tutorial","title":"Some tutorials from SciPy meeting"},{"location":"sswidl/","text":"SSWIDL \u00b6 Installation \u00b6 Install Solar Soft IDL (SSWIDL) following those instructions SSWIDL_INSTALL . Choose the following packages: chianti ontology aia iris hmi Terminal configuration \u00b6 Once installed, configurate your terminal to use SSWIDL. In your home directory, in the .login file you need to define the system variable SSW as the location of your SSW installation, e.g.: setenv SSW \"/Users/yourname/ssw\" Then you need to define the SSW_INSTR with the list of instruments you have included in the installation. setenv SSW_INSTR \"chianti ontology aia iris hmi\" Finally, add the following line in your .log file source $SSW /gen/setup/setup.ssw /quiet","title":"SSWIDL"},{"location":"sswidl/#sswidl","text":"","title":"SSWIDL"},{"location":"sswidl/#installation","text":"Install Solar Soft IDL (SSWIDL) following those instructions SSWIDL_INSTALL . Choose the following packages: chianti ontology aia iris hmi","title":"Installation"},{"location":"sswidl/#terminal-configuration","text":"Once installed, configurate your terminal to use SSWIDL. In your home directory, in the .login file you need to define the system variable SSW as the location of your SSW installation, e.g.: setenv SSW \"/Users/yourname/ssw\" Then you need to define the SSW_INSTR with the list of instruments you have included in the installation. setenv SSW_INSTR \"chianti ontology aia iris hmi\" Finally, add the following line in your .log file source $SSW /gen/setup/setup.ssw /quiet","title":"Terminal configuration"},{"location":"unix/","text":"Unix useful commands \u00b6 Documentation in process...","title":"UNIX"},{"location":"unix/#unix-useful-commands","text":"Documentation in process...","title":"Unix useful commands"}]}